{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af577d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnhquanst\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import models\n",
    "sys.path.append(\"./libs\")  # Adds higher directory to python modules path.\n",
    "from utils import accuracy, AverageMeter,ProgressMeter, Logger, save_checkpoint\n",
    "from dataManager import AfosrDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import torchvision.datasets as datasets\n",
    "import wandb\n",
    "wandb.login(timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480a9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion_xent, optimizer, trainloader, device):\n",
    "    model.train()\n",
    "    global print_freq\n",
    "    losses = AverageMeter('training loss')\n",
    "    for batch_idx,(imgs, targets) in enumerate(trainloader):\n",
    "        imgs, targets = imgs.cuda(device), targets.cuda(device)        \n",
    "        outputs, features = model(imgs)\n",
    "        xent_loss = criterion_xent(outputs, targets) # cross entropy loss     \n",
    "        loss= xent_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.update(loss.data, targets.size(0))   \n",
    "        acc1, acc5,acc10 = accuracy(outputs, targets, topk=(1, 5,10))\n",
    "        trainlog={\n",
    "            \"train_acc_top1\":acc1,\n",
    "            \"train_acc_top5\":acc5,\n",
    "            \"train_acc_top10\":acc10,\n",
    "        }\n",
    "#         wandb.log(trainlog)        \n",
    "        if (batch_idx+1) % config.print_freq == 0:\n",
    "            print(\"Train batch {}/{}\\t Loss {:.6f} ({:.6f})\"\n",
    "                  .format(batch_idx+1, len(trainloader), losses.val, losses.avg))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8506d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion_xent, val_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    global print_freq\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.3f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.3f')\n",
    "    top10 = AverageMeter('Acc@10', ':6.3f')\n",
    "\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5, top10],\n",
    "        prefix='Test:')    \n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for batch_idx,(imgs, targets) in enumerate(val_loader):\n",
    "            imgs, targets = imgs.cuda(device), targets.cuda(device)            \n",
    "            outputs, features = model(imgs)\n",
    "            xent_loss = criterion_xent(outputs, targets) # cross entropy loss           \n",
    "            loss= xent_loss\n",
    "            losses.update(loss.data, imgs.size(0))\n",
    "            \n",
    "            acc1, acc5,acc10 = accuracy(outputs, targets, topk=(1, 5,10))            \n",
    "            top1.update(acc1[0], imgs.size(0))\n",
    "            top5.update(acc5[0], imgs.size(0))\n",
    "            top10.update(acc10[0], imgs.size(0))\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            if batch_idx % config.print_freq == 0:\n",
    "                progress.display(batch_idx)\n",
    "            \n",
    "            vallog={\n",
    "                \"val_acc_top1\":acc1,\n",
    "                \"val_acc_top5\":acc5,\n",
    "                \"val_acc_top10\":acc10,\n",
    "            }\n",
    "#             wandb.log(vallog)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f} Acc@10 {top10.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5, top10=top10))\n",
    "    return losses.avg,top1.avg, top5.avg, top10.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fb76b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/works/projectComvis/AFOSR-2020/image_classification/wandb/run-20220607_211748-2kkk3gzw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nhquanst/Afosr_2022_MHI/runs/2kkk3gzw\" target=\"_blank\">misunderstood-aardvark-14</a></strong> to <a href=\"https://wandb.ai/nhquanst/Afosr_2022_MHI\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train item: 3633\n",
      "Test item: 1775\n",
      "Initializing model: resnet18\n",
      "Model size: 11.18267M\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"799.6333333333333\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 1/50\n",
      "Train batch 10/114\t Loss 2.518686 (2.525502)\n",
      "Train batch 20/114\t Loss 2.568882 (2.542756)\n",
      "Train batch 30/114\t Loss 2.503638 (2.535503)\n",
      "Train batch 40/114\t Loss 2.354614 (2.514444)\n",
      "Train batch 50/114\t Loss 2.216760 (2.483389)\n",
      "Train batch 60/114\t Loss 2.558715 (2.463767)\n",
      "Train batch 70/114\t Loss 2.336121 (2.425977)\n",
      "Train batch 80/114\t Loss 2.140638 (2.399054)\n",
      "Train batch 90/114\t Loss 1.951316 (2.364647)\n",
      "Train batch 100/114\t Loss 1.930096 (2.327608)\n",
      "Train batch 110/114\t Loss 1.859921 (2.298130)\n",
      "Test:[  0/111]\tTime  0.682( 0.682)\tLoss 1.6956e+00(1.6956e+00)\tAcc@1 37.500(37.500)\tAcc@5 81.250(81.250)\tAcc@10 100.000(100.000)\n",
      "Test:[ 10/111]\tTime  0.090( 0.156)\tLoss 1.9287e+00(1.9151e+00)\tAcc@1 31.250(32.386)\tAcc@5 81.250(80.682)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.420( 0.149)\tLoss 1.5360e+00(1.7898e+00)\tAcc@1 37.500(35.119)\tAcc@5 100.000(85.119)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.026( 0.132)\tLoss 1.8070e+00(1.8896e+00)\tAcc@1 31.250(31.250)\tAcc@5 100.000(83.669)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.401( 0.135)\tLoss 2.8704e+00(1.9696e+00)\tAcc@1 25.000(29.726)\tAcc@5 50.000(82.165)\tAcc@10 81.250(98.628)\n",
      "Test:[ 50/111]\tTime  0.063( 0.127)\tLoss 1.6895e+00(1.9421e+00)\tAcc@1 43.750(30.515)\tAcc@5 87.500(82.475)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.371( 0.128)\tLoss 1.5276e+00(1.8754e+00)\tAcc@1 50.000(31.762)\tAcc@5 87.500(84.529)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.027( 0.123)\tLoss 1.6088e+00(1.8540e+00)\tAcc@1 43.750(32.394)\tAcc@5 93.750(85.651)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.369( 0.124)\tLoss 2.1273e+00(1.8493e+00)\tAcc@1 31.250(33.179)\tAcc@5 75.000(85.571)\tAcc@10 87.500(98.765)\n",
      "Test:[ 90/111]\tTime  0.068( 0.121)\tLoss 1.7166e+00(1.8515e+00)\tAcc@1 37.500(32.418)\tAcc@5 87.500(85.646)\tAcc@10 100.000(98.901)\n",
      "Test:[100/111]\tTime  0.366( 0.122)\tLoss 1.5659e+00(1.8452e+00)\tAcc@1 43.750(32.116)\tAcc@5 100.000(86.139)\tAcc@10 100.000(99.010)\n",
      "Test:[110/111]\tTime  0.042( 0.119)\tLoss 2.1179e+00(1.8372e+00)\tAcc@1 13.333(32.563)\tAcc@5 73.333(85.915)\tAcc@10 86.667(98.930)\n",
      " * Acc@1 32.563 Acc@5 85.915 Acc@10 98.930\n",
      "==> Epoch 2/50\n",
      "Train batch 10/114\t Loss 1.889451 (1.898297)\n",
      "Train batch 20/114\t Loss 1.692013 (1.868061)\n",
      "Train batch 30/114\t Loss 2.053347 (1.849183)\n",
      "Train batch 40/114\t Loss 1.525183 (1.862628)\n",
      "Train batch 50/114\t Loss 1.897560 (1.868504)\n",
      "Train batch 60/114\t Loss 1.699913 (1.858371)\n",
      "Train batch 70/114\t Loss 1.692364 (1.847909)\n",
      "Train batch 80/114\t Loss 2.025134 (1.843369)\n",
      "Train batch 90/114\t Loss 1.532886 (1.831249)\n",
      "Train batch 100/114\t Loss 1.404514 (1.811823)\n",
      "Train batch 110/114\t Loss 1.477973 (1.790339)\n",
      "Test:[  0/111]\tTime  0.652( 0.652)\tLoss 1.8252e+00(1.8252e+00)\tAcc@1 56.250(56.250)\tAcc@5 81.250(81.250)\tAcc@10 100.000(100.000)\n",
      "Test:[ 10/111]\tTime  0.076( 0.153)\tLoss 1.7562e+00(1.7239e+00)\tAcc@1 43.750(46.591)\tAcc@5 75.000(81.818)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.383( 0.142)\tLoss 1.4698e+00(1.6119e+00)\tAcc@1 62.500(48.810)\tAcc@5 81.250(85.417)\tAcc@10 100.000(99.107)\n",
      "Test:[ 30/111]\tTime  0.050( 0.127)\tLoss 1.3569e+00(1.7719e+00)\tAcc@1 43.750(43.145)\tAcc@5 100.000(82.460)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.362( 0.128)\tLoss 2.5835e+00(1.8339e+00)\tAcc@1 25.000(41.768)\tAcc@5 56.250(82.165)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.063( 0.122)\tLoss 1.4667e+00(1.7928e+00)\tAcc@1 37.500(41.176)\tAcc@5 93.750(83.333)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.289( 0.123)\tLoss 1.6388e+00(1.7263e+00)\tAcc@1 50.000(42.930)\tAcc@5 81.250(84.939)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.112( 0.120)\tLoss 2.0987e+00(1.7461e+00)\tAcc@1 31.250(42.518)\tAcc@5 75.000(84.331)\tAcc@10 93.750(98.768)\n",
      "Test:[ 80/111]\tTime  0.283( 0.120)\tLoss 2.5855e+00(1.7592e+00)\tAcc@1 37.500(42.901)\tAcc@5 75.000(84.182)\tAcc@10 93.750(98.765)\n",
      "Test:[ 90/111]\tTime  0.131( 0.118)\tLoss 1.3485e+00(1.7469e+00)\tAcc@1 56.250(43.132)\tAcc@5 100.000(84.684)\tAcc@10 100.000(98.626)\n",
      "Test:[100/111]\tTime  0.341( 0.119)\tLoss 1.4161e+00(1.7055e+00)\tAcc@1 43.750(43.936)\tAcc@5 87.500(85.520)\tAcc@10 100.000(98.639)\n",
      "Test:[110/111]\tTime  0.058( 0.117)\tLoss 2.1750e+00(1.7247e+00)\tAcc@1 33.333(43.606)\tAcc@5 73.333(85.239)\tAcc@10 86.667(98.197)\n",
      " * Acc@1 43.606 Acc@5 85.239 Acc@10 98.197\n",
      "==> Epoch 3/50\n",
      "Train batch 10/114\t Loss 1.377890 (1.513310)\n",
      "Train batch 20/114\t Loss 1.147882 (1.479938)\n",
      "Train batch 30/114\t Loss 1.276886 (1.475558)\n",
      "Train batch 40/114\t Loss 1.329967 (1.482635)\n",
      "Train batch 50/114\t Loss 1.291658 (1.440722)\n",
      "Train batch 60/114\t Loss 1.301757 (1.446648)\n",
      "Train batch 70/114\t Loss 1.286836 (1.448226)\n",
      "Train batch 80/114\t Loss 1.513469 (1.443385)\n",
      "Train batch 90/114\t Loss 1.528098 (1.443412)\n",
      "Train batch 100/114\t Loss 1.238508 (1.440895)\n",
      "Train batch 110/114\t Loss 1.201283 (1.425814)\n",
      "Test:[  0/111]\tTime  0.650( 0.650)\tLoss 1.3680e+00(1.3680e+00)\tAcc@1 62.500(62.500)\tAcc@5 81.250(81.250)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.030( 0.146)\tLoss 1.7749e+00(1.6609e+00)\tAcc@1 56.250(50.000)\tAcc@5 81.250(81.250)\tAcc@10 93.750(94.318)\n",
      "Test:[ 20/111]\tTime  0.411( 0.141)\tLoss 1.0723e+00(1.5408e+00)\tAcc@1 68.750(52.083)\tAcc@5 93.750(85.119)\tAcc@10 100.000(95.833)\n",
      "Test:[ 30/111]\tTime  0.021( 0.126)\tLoss 1.3452e+00(1.7621e+00)\tAcc@1 62.500(48.185)\tAcc@5 93.750(81.048)\tAcc@10 100.000(94.153)\n",
      "Test:[ 40/111]\tTime  0.424( 0.128)\tLoss 3.1230e+00(1.8745e+00)\tAcc@1 25.000(46.341)\tAcc@5 62.500(79.116)\tAcc@10 81.250(93.750)\n",
      "Test:[ 50/111]\tTime  0.015( 0.121)\tLoss 1.8190e+00(1.9036e+00)\tAcc@1 31.250(44.730)\tAcc@5 93.750(78.676)\tAcc@10 93.750(93.382)\n",
      "Test:[ 60/111]\tTime  0.394( 0.123)\tLoss 1.9635e+00(1.8954e+00)\tAcc@1 56.250(44.467)\tAcc@5 81.250(79.508)\tAcc@10 100.000(93.648)\n",
      "Test:[ 70/111]\tTime  0.018( 0.119)\tLoss 2.3630e+00(1.8968e+00)\tAcc@1 25.000(43.398)\tAcc@5 68.750(79.930)\tAcc@10 87.500(94.014)\n",
      "Test:[ 80/111]\tTime  0.365( 0.120)\tLoss 2.5102e+00(1.9077e+00)\tAcc@1 18.750(42.438)\tAcc@5 68.750(79.552)\tAcc@10 93.750(93.981)\n",
      "Test:[ 90/111]\tTime  0.028( 0.117)\tLoss 1.4438e+00(1.9175e+00)\tAcc@1 56.250(42.170)\tAcc@5 93.750(79.396)\tAcc@10 100.000(93.887)\n",
      "Test:[100/111]\tTime  0.362( 0.119)\tLoss 2.0905e+00(1.8854e+00)\tAcc@1 37.500(42.203)\tAcc@5 75.000(80.198)\tAcc@10 93.750(94.369)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 1.9463e+00(1.8981e+00)\tAcc@1 40.000(42.197)\tAcc@5 80.000(80.113)\tAcc@10 86.667(93.746)\n",
      " * Acc@1 42.197 Acc@5 80.113 Acc@10 93.746\n",
      "==> Epoch 4/50\n",
      "Train batch 10/114\t Loss 1.198876 (1.179275)\n",
      "Train batch 20/114\t Loss 1.179027 (1.165088)\n",
      "Train batch 30/114\t Loss 1.183508 (1.163862)\n",
      "Train batch 40/114\t Loss 0.932452 (1.131526)\n",
      "Train batch 50/114\t Loss 1.054888 (1.123680)\n",
      "Train batch 60/114\t Loss 1.207424 (1.142822)\n",
      "Train batch 70/114\t Loss 0.842578 (1.135731)\n",
      "Train batch 80/114\t Loss 0.835383 (1.137121)\n",
      "Train batch 90/114\t Loss 1.217552 (1.142286)\n",
      "Train batch 100/114\t Loss 0.887207 (1.146250)\n",
      "Train batch 110/114\t Loss 1.374276 (1.137328)\n",
      "Test:[  0/111]\tTime  0.650( 0.650)\tLoss 2.0858e+00(2.0858e+00)\tAcc@1 56.250(56.250)\tAcc@5 81.250(81.250)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.030( 0.146)\tLoss 1.8443e+00(2.0987e+00)\tAcc@1 50.000(48.295)\tAcc@5 81.250(81.250)\tAcc@10 100.000(97.727)\n",
      "Test:[ 20/111]\tTime  0.401( 0.140)\tLoss 1.6533e+00(1.9247e+00)\tAcc@1 56.250(48.214)\tAcc@5 87.500(84.821)\tAcc@10 100.000(98.810)\n",
      "Test:[ 30/111]\tTime  0.017( 0.125)\tLoss 2.0403e+00(2.2754e+00)\tAcc@1 50.000(42.944)\tAcc@5 87.500(81.855)\tAcc@10 100.000(98.589)\n",
      "Test:[ 40/111]\tTime  0.378( 0.127)\tLoss 3.8275e+00(2.4348e+00)\tAcc@1 31.250(42.226)\tAcc@5 62.500(79.116)\tAcc@10 93.750(97.866)\n",
      "Test:[ 50/111]\tTime  0.018( 0.120)\tLoss 1.9821e+00(2.4368e+00)\tAcc@1 43.750(41.789)\tAcc@5 81.250(80.515)\tAcc@10 100.000(97.917)\n",
      "Test:[ 60/111]\tTime  0.393( 0.122)\tLoss 1.6018e+00(2.3097e+00)\tAcc@1 56.250(42.623)\tAcc@5 93.750(82.684)\tAcc@10 100.000(98.258)\n",
      "Test:[ 70/111]\tTime  0.015( 0.118)\tLoss 1.7301e+00(2.2554e+00)\tAcc@1 37.500(42.606)\tAcc@5 93.750(83.539)\tAcc@10 100.000(98.415)\n",
      "Test:[ 80/111]\tTime  0.359( 0.119)\tLoss 3.2329e+00(2.2640e+00)\tAcc@1 50.000(42.438)\tAcc@5 68.750(83.102)\tAcc@10 93.750(98.225)\n",
      "Test:[ 90/111]\tTime  0.064( 0.118)\tLoss 1.3011e+00(2.1979e+00)\tAcc@1 75.000(43.475)\tAcc@5 87.500(83.585)\tAcc@10 100.000(98.420)\n",
      "Test:[100/111]\tTime  0.272( 0.118)\tLoss 1.3815e+00(2.1284e+00)\tAcc@1 43.750(44.431)\tAcc@5 100.000(84.777)\tAcc@10 100.000(98.577)\n",
      "Test:[110/111]\tTime  0.014( 0.116)\tLoss 2.4350e+00(2.1257e+00)\tAcc@1 33.333(44.394)\tAcc@5 73.333(84.676)\tAcc@10 100.000(98.704)\n",
      " * Acc@1 44.394 Acc@5 84.676 Acc@10 98.704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 5/50\n",
      "Train batch 10/114\t Loss 1.021543 (1.016007)\n",
      "Train batch 20/114\t Loss 1.214015 (1.020689)\n",
      "Train batch 30/114\t Loss 1.236711 (1.010882)\n",
      "Train batch 40/114\t Loss 1.158862 (1.003623)\n",
      "Train batch 50/114\t Loss 0.984486 (1.015005)\n",
      "Train batch 60/114\t Loss 0.932178 (0.991788)\n",
      "Train batch 70/114\t Loss 1.222865 (0.974805)\n",
      "Train batch 80/114\t Loss 1.054845 (0.962234)\n",
      "Train batch 90/114\t Loss 1.237264 (0.964119)\n",
      "Train batch 100/114\t Loss 0.729418 (0.966268)\n",
      "Train batch 110/114\t Loss 0.886488 (0.965537)\n",
      "Test:[  0/111]\tTime  0.651( 0.651)\tLoss 1.2024e+00(1.2024e+00)\tAcc@1 81.250(81.250)\tAcc@5 87.500(87.500)\tAcc@10 100.000(100.000)\n",
      "Test:[ 10/111]\tTime  0.016( 0.147)\tLoss 1.3356e+00(1.3314e+00)\tAcc@1 62.500(61.932)\tAcc@5 93.750(88.636)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.413( 0.141)\tLoss 1.2257e+00(1.3155e+00)\tAcc@1 56.250(60.417)\tAcc@5 93.750(91.667)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.015( 0.128)\tLoss 9.3849e-01(1.7225e+00)\tAcc@1 68.750(53.831)\tAcc@5 93.750(87.097)\tAcc@10 100.000(97.984)\n",
      "Test:[ 40/111]\tTime  0.406( 0.129)\tLoss 3.0995e+00(1.8519e+00)\tAcc@1 37.500(51.372)\tAcc@5 68.750(84.146)\tAcc@10 100.000(97.866)\n",
      "Test:[ 50/111]\tTime  0.019( 0.122)\tLoss 1.5108e+00(1.8493e+00)\tAcc@1 50.000(50.490)\tAcc@5 87.500(84.436)\tAcc@10 100.000(98.162)\n",
      "Test:[ 60/111]\tTime  0.417( 0.124)\tLoss 1.1562e+00(1.6810e+00)\tAcc@1 43.750(53.176)\tAcc@5 100.000(86.885)\tAcc@10 100.000(98.463)\n",
      "Test:[ 70/111]\tTime  0.015( 0.119)\tLoss 1.5350e+00(1.6129e+00)\tAcc@1 50.000(53.521)\tAcc@5 81.250(87.764)\tAcc@10 100.000(98.592)\n",
      "Test:[ 80/111]\tTime  0.410( 0.120)\tLoss 3.3278e+00(1.6771e+00)\tAcc@1 12.500(51.620)\tAcc@5 62.500(86.806)\tAcc@10 81.250(97.994)\n",
      "Test:[ 90/111]\tTime  0.015( 0.118)\tLoss 4.4105e-01(1.6544e+00)\tAcc@1 87.500(51.374)\tAcc@5 100.000(87.157)\tAcc@10 100.000(98.146)\n",
      "Test:[100/111]\tTime  0.407( 0.119)\tLoss 1.1316e+00(1.5868e+00)\tAcc@1 56.250(52.908)\tAcc@5 100.000(88.057)\tAcc@10 100.000(98.144)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 2.5664e+00(1.6300e+00)\tAcc@1 40.000(52.169)\tAcc@5 80.000(87.437)\tAcc@10 100.000(97.859)\n",
      " * Acc@1 52.169 Acc@5 87.437 Acc@10 97.859\n",
      "==> Epoch 6/50\n",
      "Train batch 10/114\t Loss 0.932579 (0.850195)\n",
      "Train batch 20/114\t Loss 0.846524 (0.826747)\n",
      "Train batch 30/114\t Loss 0.961345 (0.860047)\n",
      "Train batch 40/114\t Loss 0.467002 (0.869699)\n",
      "Train batch 50/114\t Loss 0.879538 (0.895905)\n",
      "Train batch 60/114\t Loss 0.630413 (0.886873)\n",
      "Train batch 70/114\t Loss 0.712438 (0.878452)\n",
      "Train batch 80/114\t Loss 0.677391 (0.883299)\n",
      "Train batch 90/114\t Loss 0.911674 (0.883840)\n",
      "Train batch 100/114\t Loss 0.880116 (0.886310)\n",
      "Train batch 110/114\t Loss 0.386476 (0.880920)\n",
      "Test:[  0/111]\tTime  0.651( 0.651)\tLoss 6.9795e-01(6.9795e-01)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 100.000(100.000)\n",
      "Test:[ 10/111]\tTime  0.018( 0.147)\tLoss 8.8458e-01(1.1685e+00)\tAcc@1 75.000(65.909)\tAcc@5 100.000(91.477)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.385( 0.142)\tLoss 9.9385e-01(1.1523e+00)\tAcc@1 62.500(62.500)\tAcc@5 93.750(92.857)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.088( 0.128)\tLoss 6.9280e-01(1.4430e+00)\tAcc@1 81.250(56.250)\tAcc@5 100.000(89.718)\tAcc@10 100.000(99.395)\n",
      "Test:[ 40/111]\tTime  0.364( 0.128)\tLoss 2.6743e+00(1.5428e+00)\tAcc@1 25.000(53.811)\tAcc@5 75.000(88.567)\tAcc@10 87.500(98.933)\n",
      "Test:[ 50/111]\tTime  0.031( 0.122)\tLoss 1.7800e+00(1.6027e+00)\tAcc@1 50.000(53.186)\tAcc@5 81.250(87.377)\tAcc@10 100.000(98.897)\n",
      "Test:[ 60/111]\tTime  0.366( 0.123)\tLoss 1.4391e+00(1.5256e+00)\tAcc@1 56.250(54.201)\tAcc@5 87.500(88.627)\tAcc@10 100.000(99.078)\n",
      "Test:[ 70/111]\tTime  0.053( 0.119)\tLoss 1.2506e+00(1.5006e+00)\tAcc@1 50.000(53.785)\tAcc@5 93.750(89.349)\tAcc@10 100.000(99.208)\n",
      "Test:[ 80/111]\tTime  0.319( 0.120)\tLoss 2.8585e+00(1.5565e+00)\tAcc@1 18.750(52.623)\tAcc@5 68.750(88.426)\tAcc@10 100.000(99.228)\n",
      "Test:[ 90/111]\tTime  0.140( 0.119)\tLoss 1.3027e+00(1.5587e+00)\tAcc@1 68.750(51.992)\tAcc@5 93.750(88.874)\tAcc@10 100.000(99.313)\n",
      "Test:[100/111]\tTime  0.222( 0.119)\tLoss 1.3253e+00(1.5308e+00)\tAcc@1 56.250(52.104)\tAcc@5 93.750(89.728)\tAcc@10 100.000(99.381)\n",
      "Test:[110/111]\tTime  0.162( 0.118)\tLoss 2.0691e+00(1.5686e+00)\tAcc@1 53.333(51.211)\tAcc@5 66.667(88.563)\tAcc@10 93.333(99.380)\n",
      " * Acc@1 51.211 Acc@5 88.563 Acc@10 99.380\n",
      "==> Epoch 7/50\n",
      "Train batch 10/114\t Loss 0.897503 (0.771176)\n",
      "Train batch 20/114\t Loss 0.923156 (0.731368)\n",
      "Train batch 30/114\t Loss 1.091794 (0.732988)\n",
      "Train batch 40/114\t Loss 0.782000 (0.748104)\n",
      "Train batch 50/114\t Loss 0.850705 (0.748930)\n",
      "Train batch 60/114\t Loss 0.607938 (0.734095)\n",
      "Train batch 70/114\t Loss 0.746210 (0.750965)\n",
      "Train batch 80/114\t Loss 0.597325 (0.741318)\n",
      "Train batch 90/114\t Loss 0.909666 (0.746901)\n",
      "Train batch 100/114\t Loss 0.750806 (0.749732)\n",
      "Train batch 110/114\t Loss 0.963900 (0.749755)\n",
      "Test:[  0/111]\tTime  0.721( 0.721)\tLoss 1.0700e+00(1.0700e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 100.000(100.000)\n",
      "Test:[ 10/111]\tTime  0.016( 0.153)\tLoss 1.1076e+00(1.3345e+00)\tAcc@1 62.500(56.818)\tAcc@5 100.000(92.614)\tAcc@10 100.000(100.000)\n",
      "Test:[ 20/111]\tTime  0.418( 0.145)\tLoss 1.3866e+00(1.3088e+00)\tAcc@1 56.250(58.929)\tAcc@5 93.750(93.452)\tAcc@10 100.000(100.000)\n",
      "Test:[ 30/111]\tTime  0.014( 0.129)\tLoss 7.3081e-01(1.5720e+00)\tAcc@1 81.250(54.032)\tAcc@5 100.000(90.121)\tAcc@10 100.000(99.194)\n",
      "Test:[ 40/111]\tTime  0.411( 0.130)\tLoss 2.5994e+00(1.6236e+00)\tAcc@1 43.750(54.116)\tAcc@5 81.250(89.482)\tAcc@10 93.750(99.085)\n",
      "Test:[ 50/111]\tTime  0.015( 0.123)\tLoss 1.0519e+00(1.5984e+00)\tAcc@1 68.750(54.657)\tAcc@5 93.750(90.319)\tAcc@10 100.000(99.020)\n",
      "Test:[ 60/111]\tTime  0.426( 0.125)\tLoss 1.0464e+00(1.5471e+00)\tAcc@1 56.250(54.098)\tAcc@5 100.000(91.393)\tAcc@10 100.000(99.180)\n",
      "Test:[ 70/111]\tTime  0.018( 0.120)\tLoss 1.1770e+00(1.4872e+00)\tAcc@1 68.750(55.018)\tAcc@5 93.750(91.901)\tAcc@10 100.000(99.296)\n",
      "Test:[ 80/111]\tTime  0.390( 0.122)\tLoss 2.3970e+00(1.5168e+00)\tAcc@1 43.750(54.861)\tAcc@5 75.000(90.586)\tAcc@10 93.750(99.228)\n",
      "Test:[ 90/111]\tTime  0.014( 0.119)\tLoss 5.0526e-01(1.4810e+00)\tAcc@1 81.250(54.739)\tAcc@5 100.000(91.071)\tAcc@10 100.000(99.313)\n",
      "Test:[100/111]\tTime  0.413( 0.120)\tLoss 1.0762e+00(1.4193e+00)\tAcc@1 37.500(55.879)\tAcc@5 100.000(91.955)\tAcc@10 100.000(99.381)\n",
      "Test:[110/111]\tTime  0.013( 0.117)\tLoss 2.0074e+00(1.4534e+00)\tAcc@1 46.667(54.873)\tAcc@5 80.000(91.324)\tAcc@10 100.000(99.380)\n",
      " * Acc@1 54.873 Acc@5 91.324 Acc@10 99.380\n",
      "==> Epoch 8/50\n",
      "Train batch 10/114\t Loss 0.683012 (0.642890)\n",
      "Train batch 20/114\t Loss 0.404833 (0.622590)\n",
      "Train batch 30/114\t Loss 0.871943 (0.661169)\n",
      "Train batch 40/114\t Loss 0.927825 (0.659445)\n",
      "Train batch 50/114\t Loss 0.933668 (0.646432)\n",
      "Train batch 60/114\t Loss 0.533414 (0.626278)\n",
      "Train batch 70/114\t Loss 0.671965 (0.618041)\n",
      "Train batch 80/114\t Loss 0.861626 (0.634253)\n",
      "Train batch 90/114\t Loss 0.515341 (0.634241)\n",
      "Train batch 100/114\t Loss 0.912908 (0.640935)\n",
      "Train batch 110/114\t Loss 0.801491 (0.649381)\n",
      "Test:[  0/111]\tTime  0.654( 0.654)\tLoss 1.2417e+00(1.2417e+00)\tAcc@1 62.500(62.500)\tAcc@5 87.500(87.500)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.015( 0.149)\tLoss 1.0808e+00(1.4244e+00)\tAcc@1 68.750(52.841)\tAcc@5 93.750(89.773)\tAcc@10 100.000(98.295)\n",
      "Test:[ 20/111]\tTime  0.361( 0.141)\tLoss 1.2394e+00(1.3604e+00)\tAcc@1 56.250(57.440)\tAcc@5 93.750(91.369)\tAcc@10 100.000(99.107)\n",
      "Test:[ 30/111]\tTime  0.018( 0.128)\tLoss 1.2891e+00(1.6914e+00)\tAcc@1 62.500(50.202)\tAcc@5 100.000(88.306)\tAcc@10 100.000(98.589)\n",
      "Test:[ 40/111]\tTime  0.338( 0.128)\tLoss 2.6580e+00(1.8352e+00)\tAcc@1 43.750(48.476)\tAcc@5 81.250(86.128)\tAcc@10 100.000(98.171)\n",
      "Test:[ 50/111]\tTime  0.015( 0.123)\tLoss 2.1498e+00(1.8816e+00)\tAcc@1 50.000(48.897)\tAcc@5 81.250(85.417)\tAcc@10 100.000(98.407)\n",
      "Test:[ 60/111]\tTime  0.319( 0.123)\tLoss 1.1240e+00(1.7899e+00)\tAcc@1 62.500(49.795)\tAcc@5 93.750(87.193)\tAcc@10 100.000(98.668)\n",
      "Test:[ 70/111]\tTime  0.014( 0.120)\tLoss 1.1052e+00(1.7038e+00)\tAcc@1 50.000(50.616)\tAcc@5 93.750(88.380)\tAcc@10 100.000(98.856)\n",
      "Test:[ 80/111]\tTime  0.265( 0.120)\tLoss 2.8886e+00(1.7160e+00)\tAcc@1 18.750(50.463)\tAcc@5 75.000(87.809)\tAcc@10 87.500(98.688)\n",
      "Test:[ 90/111]\tTime  0.015( 0.119)\tLoss 6.2981e-01(1.7032e+00)\tAcc@1 68.750(50.206)\tAcc@5 100.000(87.775)\tAcc@10 100.000(98.832)\n",
      "Test:[100/111]\tTime  0.253( 0.119)\tLoss 9.8291e-01(1.6247e+00)\tAcc@1 62.500(51.733)\tAcc@5 100.000(88.985)\tAcc@10 100.000(98.948)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[110/111]\tTime  0.012( 0.117)\tLoss 1.9514e+00(1.6318e+00)\tAcc@1 60.000(51.268)\tAcc@5 73.333(88.620)\tAcc@10 100.000(99.042)\n",
      " * Acc@1 51.268 Acc@5 88.620 Acc@10 99.042\n",
      "==> Epoch 9/50\n",
      "Train batch 10/114\t Loss 0.369685 (0.508972)\n",
      "Train batch 20/114\t Loss 0.761676 (0.572442)\n",
      "Train batch 30/114\t Loss 0.699263 (0.554892)\n",
      "Train batch 40/114\t Loss 0.489578 (0.544471)\n",
      "Train batch 50/114\t Loss 0.579804 (0.556225)\n",
      "Train batch 60/114\t Loss 0.759496 (0.547339)\n",
      "Train batch 70/114\t Loss 0.445255 (0.549881)\n",
      "Train batch 80/114\t Loss 0.535918 (0.547144)\n",
      "Train batch 90/114\t Loss 0.570789 (0.554692)\n",
      "Train batch 100/114\t Loss 0.566791 (0.558724)\n",
      "Train batch 110/114\t Loss 0.322060 (0.562596)\n",
      "Test:[  0/111]\tTime  0.653( 0.653)\tLoss 1.8246e+00(1.8246e+00)\tAcc@1 75.000(75.000)\tAcc@5 87.500(87.500)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.030( 0.147)\tLoss 1.4399e+00(1.7503e+00)\tAcc@1 68.750(55.682)\tAcc@5 87.500(85.795)\tAcc@10 100.000(97.727)\n",
      "Test:[ 20/111]\tTime  0.405( 0.141)\tLoss 1.4830e+00(1.6309e+00)\tAcc@1 56.250(53.571)\tAcc@5 100.000(91.369)\tAcc@10 100.000(98.810)\n",
      "Test:[ 30/111]\tTime  0.016( 0.126)\tLoss 1.6062e+00(2.1313e+00)\tAcc@1 50.000(45.968)\tAcc@5 87.500(87.097)\tAcc@10 100.000(98.589)\n",
      "Test:[ 40/111]\tTime  0.352( 0.127)\tLoss 3.5015e+00(2.3064e+00)\tAcc@1 31.250(44.512)\tAcc@5 68.750(84.604)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.016( 0.120)\tLoss 1.4745e+00(2.2504e+00)\tAcc@1 62.500(45.588)\tAcc@5 81.250(84.804)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.356( 0.122)\tLoss 1.0650e+00(2.1014e+00)\tAcc@1 56.250(47.848)\tAcc@5 93.750(86.783)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.016( 0.118)\tLoss 1.4439e+00(1.9888e+00)\tAcc@1 50.000(48.944)\tAcc@5 100.000(88.292)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.316( 0.119)\tLoss 3.3258e+00(1.9904e+00)\tAcc@1 18.750(48.843)\tAcc@5 68.750(87.886)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.033( 0.117)\tLoss 8.5314e-01(1.9571e+00)\tAcc@1 68.750(48.695)\tAcc@5 100.000(88.324)\tAcc@10 100.000(99.038)\n",
      "Test:[100/111]\tTime  0.319( 0.118)\tLoss 1.0796e+00(1.8787e+00)\tAcc@1 68.750(50.062)\tAcc@5 100.000(89.356)\tAcc@10 100.000(99.134)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 2.1190e+00(1.8998e+00)\tAcc@1 40.000(49.690)\tAcc@5 86.667(89.070)\tAcc@10 100.000(99.099)\n",
      " * Acc@1 49.690 Acc@5 89.070 Acc@10 99.099\n",
      "==> Epoch 10/50\n",
      "Train batch 10/114\t Loss 0.490950 (0.584172)\n",
      "Train batch 20/114\t Loss 0.240415 (0.538100)\n",
      "Train batch 30/114\t Loss 0.567616 (0.519734)\n",
      "Train batch 40/114\t Loss 0.365958 (0.505437)\n",
      "Train batch 50/114\t Loss 0.458773 (0.507587)\n",
      "Train batch 60/114\t Loss 0.530955 (0.500212)\n",
      "Train batch 70/114\t Loss 0.583040 (0.501426)\n",
      "Train batch 80/114\t Loss 0.508568 (0.505692)\n",
      "Train batch 90/114\t Loss 0.486617 (0.510469)\n",
      "Train batch 100/114\t Loss 0.806665 (0.522504)\n",
      "Train batch 110/114\t Loss 0.408364 (0.520857)\n",
      "Test:[  0/111]\tTime  0.653( 0.653)\tLoss 2.2592e+00(2.2592e+00)\tAcc@1 50.000(50.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.027( 0.146)\tLoss 1.0569e+00(1.9367e+00)\tAcc@1 62.500(46.023)\tAcc@5 100.000(88.068)\tAcc@10 100.000(98.295)\n",
      "Test:[ 20/111]\tTime  0.412( 0.141)\tLoss 1.8693e+00(1.9088e+00)\tAcc@1 56.250(48.512)\tAcc@5 100.000(89.286)\tAcc@10 100.000(98.810)\n",
      "Test:[ 30/111]\tTime  0.016( 0.125)\tLoss 2.0044e+00(2.4949e+00)\tAcc@1 43.750(42.540)\tAcc@5 93.750(83.468)\tAcc@10 100.000(96.774)\n",
      "Test:[ 40/111]\tTime  0.362( 0.127)\tLoss 3.2847e+00(2.5530e+00)\tAcc@1 31.250(42.835)\tAcc@5 68.750(81.250)\tAcc@10 93.750(96.951)\n",
      "Test:[ 50/111]\tTime  0.015( 0.121)\tLoss 1.6227e+00(2.5071e+00)\tAcc@1 50.000(43.382)\tAcc@5 87.500(81.863)\tAcc@10 100.000(97.181)\n",
      "Test:[ 60/111]\tTime  0.338( 0.122)\tLoss 1.1397e+00(2.3635e+00)\tAcc@1 62.500(45.082)\tAcc@5 93.750(83.402)\tAcc@10 100.000(97.439)\n",
      "Test:[ 70/111]\tTime  0.015( 0.118)\tLoss 3.1402e+00(2.2906e+00)\tAcc@1 31.250(45.423)\tAcc@5 75.000(84.067)\tAcc@10 100.000(97.799)\n",
      "Test:[ 80/111]\tTime  0.393( 0.120)\tLoss 4.0617e+00(2.3977e+00)\tAcc@1 25.000(43.904)\tAcc@5 62.500(82.870)\tAcc@10 93.750(97.840)\n",
      "Test:[ 90/111]\tTime  0.016( 0.117)\tLoss 2.9378e-01(2.3598e+00)\tAcc@1 93.750(44.299)\tAcc@5 100.000(83.860)\tAcc@10 100.000(98.077)\n",
      "Test:[100/111]\tTime  0.404( 0.120)\tLoss 1.6467e+00(2.2268e+00)\tAcc@1 43.750(46.906)\tAcc@5 100.000(85.149)\tAcc@10 100.000(98.267)\n",
      "Test:[110/111]\tTime  0.013( 0.117)\tLoss 3.1445e+00(2.2940e+00)\tAcc@1 26.667(45.296)\tAcc@5 80.000(84.507)\tAcc@10 100.000(98.310)\n",
      " * Acc@1 45.296 Acc@5 84.507 Acc@10 98.310\n",
      "==> Epoch 11/50\n",
      "Train batch 10/114\t Loss 0.609225 (0.427146)\n",
      "Train batch 20/114\t Loss 0.450846 (0.382136)\n",
      "Train batch 30/114\t Loss 0.231728 (0.362131)\n",
      "Train batch 40/114\t Loss 0.278379 (0.362133)\n",
      "Train batch 50/114\t Loss 0.474956 (0.365196)\n",
      "Train batch 60/114\t Loss 0.282627 (0.360767)\n",
      "Train batch 70/114\t Loss 0.467184 (0.364473)\n",
      "Train batch 80/114\t Loss 0.244170 (0.367390)\n",
      "Train batch 90/114\t Loss 0.254270 (0.366940)\n",
      "Train batch 100/114\t Loss 0.127666 (0.358103)\n",
      "Train batch 110/114\t Loss 0.321920 (0.352609)\n",
      "Test:[  0/111]\tTime  0.657( 0.657)\tLoss 1.5399e+00(1.5399e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.015( 0.150)\tLoss 7.9833e-01(1.2414e+00)\tAcc@1 81.250(65.341)\tAcc@5 93.750(91.477)\tAcc@10 100.000(97.727)\n",
      "Test:[ 20/111]\tTime  0.423( 0.144)\tLoss 1.2032e+00(1.2641e+00)\tAcc@1 68.750(63.393)\tAcc@5 100.000(94.048)\tAcc@10 100.000(98.810)\n",
      "Test:[ 30/111]\tTime  0.018( 0.128)\tLoss 9.5410e-01(1.6042e+00)\tAcc@1 75.000(57.661)\tAcc@5 93.750(90.726)\tAcc@10 100.000(98.185)\n",
      "Test:[ 40/111]\tTime  0.404( 0.129)\tLoss 2.9432e+00(1.7142e+00)\tAcc@1 37.500(56.250)\tAcc@5 68.750(88.262)\tAcc@10 93.750(97.561)\n",
      "Test:[ 50/111]\tTime  0.015( 0.122)\tLoss 1.4493e+00(1.7180e+00)\tAcc@1 62.500(56.373)\tAcc@5 93.750(88.480)\tAcc@10 100.000(97.917)\n",
      "Test:[ 60/111]\tTime  0.426( 0.124)\tLoss 8.1339e-01(1.6223e+00)\tAcc@1 68.750(57.377)\tAcc@5 100.000(90.061)\tAcc@10 100.000(98.258)\n",
      "Test:[ 70/111]\tTime  0.014( 0.120)\tLoss 1.3372e+00(1.5335e+00)\tAcc@1 62.500(58.275)\tAcc@5 93.750(91.109)\tAcc@10 100.000(98.504)\n",
      "Test:[ 80/111]\tTime  0.394( 0.122)\tLoss 2.4631e+00(1.5489e+00)\tAcc@1 50.000(58.333)\tAcc@5 68.750(90.355)\tAcc@10 93.750(98.457)\n",
      "Test:[ 90/111]\tTime  0.014( 0.119)\tLoss 5.8111e-01(1.5122e+00)\tAcc@1 75.000(58.448)\tAcc@5 100.000(90.797)\tAcc@10 100.000(98.626)\n",
      "Test:[100/111]\tTime  0.410( 0.120)\tLoss 8.1357e-01(1.4350e+00)\tAcc@1 68.750(60.272)\tAcc@5 100.000(91.646)\tAcc@10 100.000(98.762)\n",
      "Test:[110/111]\tTime  0.013( 0.118)\tLoss 2.0898e+00(1.4619e+00)\tAcc@1 46.667(59.493)\tAcc@5 86.667(91.380)\tAcc@10 100.000(98.817)\n",
      " * Acc@1 59.493 Acc@5 91.380 Acc@10 98.817\n",
      "==> Epoch 12/50\n",
      "Train batch 10/114\t Loss 0.400873 (0.318125)\n",
      "Train batch 20/114\t Loss 0.165018 (0.274826)\n",
      "Train batch 30/114\t Loss 0.278709 (0.275143)\n",
      "Train batch 40/114\t Loss 0.237623 (0.262069)\n",
      "Train batch 50/114\t Loss 0.212591 (0.276696)\n",
      "Train batch 60/114\t Loss 0.282074 (0.286029)\n",
      "Train batch 70/114\t Loss 0.297816 (0.284429)\n",
      "Train batch 80/114\t Loss 0.301165 (0.280695)\n",
      "Train batch 90/114\t Loss 0.179473 (0.286680)\n",
      "Train batch 100/114\t Loss 0.494917 (0.290101)\n",
      "Train batch 110/114\t Loss 0.505351 (0.292476)\n",
      "Test:[  0/111]\tTime  0.695( 0.695)\tLoss 1.3777e+00(1.3777e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.015( 0.150)\tLoss 6.2705e-01(1.1282e+00)\tAcc@1 81.250(64.205)\tAcc@5 100.000(93.182)\tAcc@10 100.000(97.727)\n",
      "Test:[ 20/111]\tTime  0.392( 0.142)\tLoss 1.0718e+00(1.1380e+00)\tAcc@1 62.500(62.798)\tAcc@5 100.000(95.536)\tAcc@10 100.000(98.810)\n",
      "Test:[ 30/111]\tTime  0.014( 0.127)\tLoss 8.1300e-01(1.4802e+00)\tAcc@1 75.000(57.056)\tAcc@5 93.750(92.540)\tAcc@10 100.000(98.185)\n",
      "Test:[ 40/111]\tTime  0.403( 0.128)\tLoss 2.6901e+00(1.5945e+00)\tAcc@1 43.750(55.945)\tAcc@5 87.500(90.396)\tAcc@10 93.750(97.713)\n",
      "Test:[ 50/111]\tTime  0.014( 0.121)\tLoss 1.6209e+00(1.6243e+00)\tAcc@1 50.000(55.760)\tAcc@5 87.500(90.319)\tAcc@10 100.000(98.039)\n",
      "Test:[ 60/111]\tTime  0.421( 0.123)\tLoss 8.3952e-01(1.5250e+00)\tAcc@1 62.500(57.070)\tAcc@5 100.000(91.701)\tAcc@10 100.000(98.361)\n",
      "Test:[ 70/111]\tTime  0.014( 0.119)\tLoss 9.6688e-01(1.4246e+00)\tAcc@1 62.500(58.539)\tAcc@5 100.000(92.694)\tAcc@10 100.000(98.592)\n",
      "Test:[ 80/111]\tTime  0.396( 0.120)\tLoss 2.5166e+00(1.4348e+00)\tAcc@1 43.750(58.873)\tAcc@5 68.750(91.821)\tAcc@10 93.750(98.688)\n",
      "Test:[ 90/111]\tTime  0.015( 0.118)\tLoss 4.9232e-01(1.3988e+00)\tAcc@1 81.250(58.723)\tAcc@5 100.000(92.376)\tAcc@10 100.000(98.832)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[100/111]\tTime  0.399( 0.119)\tLoss 5.6941e-01(1.3198e+00)\tAcc@1 81.250(60.891)\tAcc@5 100.000(93.069)\tAcc@10 100.000(98.948)\n",
      "Test:[110/111]\tTime  0.017( 0.117)\tLoss 1.6900e+00(1.3452e+00)\tAcc@1 60.000(60.451)\tAcc@5 80.000(92.845)\tAcc@10 100.000(99.042)\n",
      " * Acc@1 60.451 Acc@5 92.845 Acc@10 99.042\n",
      "==> Epoch 13/50\n",
      "Train batch 10/114\t Loss 0.365486 (0.275286)\n",
      "Train batch 20/114\t Loss 0.199112 (0.262142)\n",
      "Train batch 30/114\t Loss 0.223728 (0.267312)\n",
      "Train batch 40/114\t Loss 0.111482 (0.263490)\n",
      "Train batch 50/114\t Loss 0.270166 (0.263332)\n",
      "Train batch 60/114\t Loss 0.304950 (0.266498)\n",
      "Train batch 70/114\t Loss 0.308431 (0.263397)\n",
      "Train batch 80/114\t Loss 0.119624 (0.265712)\n",
      "Train batch 90/114\t Loss 0.185072 (0.262510)\n",
      "Train batch 100/114\t Loss 0.205226 (0.269089)\n",
      "Train batch 110/114\t Loss 0.254543 (0.271872)\n",
      "Test:[  0/111]\tTime  0.651( 0.651)\tLoss 1.2135e+00(1.2135e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.025( 0.146)\tLoss 5.8530e-01(1.0414e+00)\tAcc@1 81.250(66.477)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.415( 0.141)\tLoss 8.9327e-01(1.0461e+00)\tAcc@1 75.000(65.476)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.014( 0.127)\tLoss 6.7635e-01(1.3398e+00)\tAcc@1 87.500(60.282)\tAcc@5 100.000(94.960)\tAcc@10 100.000(99.194)\n",
      "Test:[ 40/111]\tTime  0.374( 0.128)\tLoss 2.5501e+00(1.4426e+00)\tAcc@1 43.750(58.841)\tAcc@5 81.250(93.293)\tAcc@10 93.750(98.628)\n",
      "Test:[ 50/111]\tTime  0.015( 0.122)\tLoss 1.5455e+00(1.4765e+00)\tAcc@1 50.000(58.701)\tAcc@5 87.500(92.770)\tAcc@10 100.000(98.897)\n",
      "Test:[ 60/111]\tTime  0.357( 0.123)\tLoss 8.7682e-01(1.4248e+00)\tAcc@1 75.000(59.324)\tAcc@5 93.750(93.648)\tAcc@10 100.000(99.078)\n",
      "Test:[ 70/111]\tTime  0.015( 0.120)\tLoss 1.0373e+00(1.3383e+00)\tAcc@1 62.500(60.387)\tAcc@5 100.000(94.454)\tAcc@10 100.000(99.208)\n",
      "Test:[ 80/111]\tTime  0.331( 0.121)\tLoss 2.1965e+00(1.3460e+00)\tAcc@1 50.000(60.802)\tAcc@5 75.000(93.519)\tAcc@10 100.000(99.306)\n",
      "Test:[ 90/111]\tTime  0.015( 0.119)\tLoss 4.6880e-01(1.3157e+00)\tAcc@1 81.250(60.302)\tAcc@5 100.000(93.956)\tAcc@10 100.000(99.382)\n",
      "Test:[100/111]\tTime  0.346( 0.120)\tLoss 7.1605e-01(1.2474e+00)\tAcc@1 68.750(61.819)\tAcc@5 100.000(94.554)\tAcc@10 100.000(99.443)\n",
      "Test:[110/111]\tTime  0.013( 0.118)\tLoss 1.6565e+00(1.2806e+00)\tAcc@1 66.667(61.239)\tAcc@5 86.667(94.310)\tAcc@10 100.000(99.493)\n",
      " * Acc@1 61.239 Acc@5 94.310 Acc@10 99.493\n",
      "==> Epoch 14/50\n",
      "Train batch 10/114\t Loss 0.322399 (0.245004)\n",
      "Train batch 20/114\t Loss 0.340684 (0.248416)\n",
      "Train batch 30/114\t Loss 0.290930 (0.248725)\n",
      "Train batch 40/114\t Loss 0.247891 (0.260734)\n",
      "Train batch 50/114\t Loss 0.152401 (0.258138)\n",
      "Train batch 60/114\t Loss 0.277656 (0.255645)\n",
      "Train batch 70/114\t Loss 0.284095 (0.258737)\n",
      "Train batch 80/114\t Loss 0.309397 (0.261582)\n",
      "Train batch 90/114\t Loss 0.259017 (0.253649)\n",
      "Train batch 100/114\t Loss 0.217501 (0.253778)\n",
      "Train batch 110/114\t Loss 0.116647 (0.252328)\n",
      "Test:[  0/111]\tTime  0.653( 0.653)\tLoss 1.2975e+00(1.2975e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.025( 0.146)\tLoss 5.5277e-01(1.0072e+00)\tAcc@1 81.250(69.318)\tAcc@5 100.000(96.023)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.413( 0.141)\tLoss 8.4123e-01(1.0416e+00)\tAcc@1 68.750(64.583)\tAcc@5 100.000(97.619)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.016( 0.125)\tLoss 7.5068e-01(1.3790e+00)\tAcc@1 62.500(59.476)\tAcc@5 100.000(94.556)\tAcc@10 100.000(99.194)\n",
      "Test:[ 40/111]\tTime  0.404( 0.128)\tLoss 2.7769e+00(1.4936e+00)\tAcc@1 37.500(57.622)\tAcc@5 75.000(92.378)\tAcc@10 93.750(98.628)\n",
      "Test:[ 50/111]\tTime  0.016( 0.121)\tLoss 1.4348e+00(1.5162e+00)\tAcc@1 62.500(57.721)\tAcc@5 87.500(91.912)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.426( 0.123)\tLoss 7.6965e-01(1.4526e+00)\tAcc@1 81.250(58.914)\tAcc@5 100.000(93.238)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.015( 0.119)\tLoss 1.0774e+00(1.3561e+00)\tAcc@1 62.500(60.475)\tAcc@5 100.000(94.102)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.394( 0.120)\tLoss 2.4653e+00(1.3647e+00)\tAcc@1 43.750(60.802)\tAcc@5 75.000(93.133)\tAcc@10 93.750(99.151)\n",
      "Test:[ 90/111]\tTime  0.014( 0.117)\tLoss 4.7365e-01(1.3243e+00)\tAcc@1 81.250(61.058)\tAcc@5 100.000(93.544)\tAcc@10 100.000(99.245)\n",
      "Test:[100/111]\tTime  0.391( 0.119)\tLoss 5.9571e-01(1.2498e+00)\tAcc@1 62.500(62.500)\tAcc@5 100.000(94.183)\tAcc@10 100.000(99.319)\n",
      "Test:[110/111]\tTime  0.012( 0.117)\tLoss 1.8689e+00(1.2886e+00)\tAcc@1 46.667(61.634)\tAcc@5 86.667(93.746)\tAcc@10 100.000(99.380)\n",
      " * Acc@1 61.634 Acc@5 93.746 Acc@10 99.380\n",
      "==> Epoch 15/50\n",
      "Train batch 10/114\t Loss 0.247247 (0.210550)\n",
      "Train batch 20/114\t Loss 0.173842 (0.202674)\n",
      "Train batch 30/114\t Loss 0.241125 (0.203818)\n",
      "Train batch 40/114\t Loss 0.300027 (0.209229)\n",
      "Train batch 50/114\t Loss 0.163528 (0.218024)\n",
      "Train batch 60/114\t Loss 0.183165 (0.218742)\n",
      "Train batch 70/114\t Loss 0.228977 (0.223860)\n",
      "Train batch 80/114\t Loss 0.209399 (0.222782)\n",
      "Train batch 90/114\t Loss 0.247055 (0.227085)\n",
      "Train batch 100/114\t Loss 0.440079 (0.230163)\n",
      "Train batch 110/114\t Loss 0.335316 (0.233334)\n",
      "Test:[  0/111]\tTime  0.654( 0.654)\tLoss 1.1986e+00(1.1986e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.016( 0.150)\tLoss 4.6235e-01(9.5212e-01)\tAcc@1 87.500(72.727)\tAcc@5 100.000(96.591)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.366( 0.141)\tLoss 8.0517e-01(9.7965e-01)\tAcc@1 62.500(67.560)\tAcc@5 100.000(97.917)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.019( 0.128)\tLoss 6.6641e-01(1.3030e+00)\tAcc@1 81.250(62.500)\tAcc@5 100.000(95.363)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.376( 0.129)\tLoss 2.6070e+00(1.4092e+00)\tAcc@1 43.750(60.518)\tAcc@5 75.000(93.293)\tAcc@10 93.750(98.628)\n",
      "Test:[ 50/111]\tTime  0.019( 0.123)\tLoss 1.5811e+00(1.4554e+00)\tAcc@1 62.500(60.172)\tAcc@5 87.500(92.647)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.434( 0.125)\tLoss 8.1744e-01(1.3960e+00)\tAcc@1 75.000(60.656)\tAcc@5 93.750(93.648)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.014( 0.120)\tLoss 9.3492e-01(1.2995e+00)\tAcc@1 68.750(61.884)\tAcc@5 100.000(94.542)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.394( 0.121)\tLoss 2.3708e+00(1.3078e+00)\tAcc@1 37.500(62.423)\tAcc@5 68.750(93.441)\tAcc@10 100.000(99.228)\n",
      "Test:[ 90/111]\tTime  0.014( 0.118)\tLoss 4.3232e-01(1.2763e+00)\tAcc@1 81.250(61.813)\tAcc@5 100.000(93.750)\tAcc@10 100.000(99.313)\n",
      "Test:[100/111]\tTime  0.414( 0.120)\tLoss 6.5681e-01(1.2066e+00)\tAcc@1 62.500(63.243)\tAcc@5 100.000(94.369)\tAcc@10 100.000(99.381)\n",
      "Test:[110/111]\tTime  0.012( 0.118)\tLoss 1.5692e+00(1.2343e+00)\tAcc@1 66.667(62.535)\tAcc@5 86.667(94.085)\tAcc@10 100.000(99.437)\n",
      " * Acc@1 62.535 Acc@5 94.085 Acc@10 99.437\n",
      "==> Epoch 16/50\n",
      "Train batch 10/114\t Loss 0.152750 (0.222044)\n",
      "Train batch 20/114\t Loss 0.170180 (0.228720)\n",
      "Train batch 30/114\t Loss 0.193717 (0.222458)\n",
      "Train batch 40/114\t Loss 0.102977 (0.215035)\n",
      "Train batch 50/114\t Loss 0.192913 (0.221098)\n",
      "Train batch 60/114\t Loss 0.280067 (0.223924)\n",
      "Train batch 70/114\t Loss 0.341355 (0.226214)\n",
      "Train batch 80/114\t Loss 0.200043 (0.226286)\n",
      "Train batch 90/114\t Loss 0.137574 (0.226031)\n",
      "Train batch 100/114\t Loss 0.205457 (0.223105)\n",
      "Train batch 110/114\t Loss 0.154673 (0.223077)\n",
      "Test:[  0/111]\tTime  0.656( 0.656)\tLoss 1.2853e+00(1.2853e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.016( 0.146)\tLoss 4.6025e-01(9.4627e-01)\tAcc@1 87.500(69.886)\tAcc@5 100.000(97.727)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.402( 0.142)\tLoss 7.9675e-01(9.6325e-01)\tAcc@1 68.750(67.262)\tAcc@5 100.000(98.512)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.014( 0.127)\tLoss 6.6681e-01(1.2979e+00)\tAcc@1 81.250(61.290)\tAcc@5 100.000(95.565)\tAcc@10 100.000(99.395)\n",
      "Test:[ 40/111]\tTime  0.408( 0.129)\tLoss 2.5549e+00(1.4070e+00)\tAcc@1 43.750(58.841)\tAcc@5 81.250(93.445)\tAcc@10 100.000(99.085)\n",
      "Test:[ 50/111]\tTime  0.014( 0.122)\tLoss 1.2787e+00(1.4199e+00)\tAcc@1 68.750(59.069)\tAcc@5 87.500(93.137)\tAcc@10 100.000(99.142)\n",
      "Test:[ 60/111]\tTime  0.417( 0.124)\tLoss 8.2635e-01(1.3583e+00)\tAcc@1 68.750(59.836)\tAcc@5 93.750(94.057)\tAcc@10 100.000(99.283)\n",
      "Test:[ 70/111]\tTime  0.015( 0.120)\tLoss 8.1669e-01(1.2696e+00)\tAcc@1 56.250(61.092)\tAcc@5 100.000(94.894)\tAcc@10 100.000(99.384)\n",
      "Test:[ 80/111]\tTime  0.388( 0.121)\tLoss 2.2593e+00(1.2821e+00)\tAcc@1 43.750(61.651)\tAcc@5 81.250(94.136)\tAcc@10 93.750(99.383)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 90/111]\tTime  0.014( 0.118)\tLoss 4.1313e-01(1.2493e+00)\tAcc@1 75.000(61.470)\tAcc@5 100.000(94.643)\tAcc@10 100.000(99.451)\n",
      "Test:[100/111]\tTime  0.407( 0.119)\tLoss 6.7335e-01(1.1845e+00)\tAcc@1 68.750(62.933)\tAcc@5 100.000(95.173)\tAcc@10 100.000(99.505)\n",
      "Test:[110/111]\tTime  0.012( 0.117)\tLoss 1.5683e+00(1.2159e+00)\tAcc@1 60.000(62.310)\tAcc@5 86.667(94.930)\tAcc@10 100.000(99.549)\n",
      " * Acc@1 62.310 Acc@5 94.930 Acc@10 99.549\n",
      "==> Epoch 17/50\n",
      "Train batch 10/114\t Loss 0.511290 (0.247283)\n",
      "Train batch 20/114\t Loss 0.172905 (0.242682)\n",
      "Train batch 30/114\t Loss 0.240740 (0.234645)\n",
      "Train batch 40/114\t Loss 0.151011 (0.224773)\n",
      "Train batch 50/114\t Loss 0.126888 (0.220133)\n",
      "Train batch 60/114\t Loss 0.296062 (0.219597)\n",
      "Train batch 70/114\t Loss 0.143399 (0.220803)\n",
      "Train batch 80/114\t Loss 0.222983 (0.222201)\n",
      "Train batch 90/114\t Loss 0.098082 (0.216586)\n",
      "Train batch 100/114\t Loss 0.396034 (0.216468)\n",
      "Train batch 110/114\t Loss 0.119931 (0.213889)\n",
      "Test:[  0/111]\tTime  0.674( 0.674)\tLoss 1.3353e+00(1.3353e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.022( 0.149)\tLoss 5.8794e-01(1.0019e+00)\tAcc@1 81.250(69.886)\tAcc@5 100.000(93.182)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.410( 0.142)\tLoss 8.4244e-01(1.0210e+00)\tAcc@1 75.000(68.155)\tAcc@5 100.000(95.833)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.098( 0.131)\tLoss 7.6226e-01(1.3410e+00)\tAcc@1 62.500(62.097)\tAcc@5 100.000(93.952)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.366( 0.130)\tLoss 2.5805e+00(1.4556e+00)\tAcc@1 37.500(59.451)\tAcc@5 75.000(91.768)\tAcc@10 100.000(98.628)\n",
      "Test:[ 50/111]\tTime  0.031( 0.124)\tLoss 1.5835e+00(1.4938e+00)\tAcc@1 62.500(59.559)\tAcc@5 87.500(91.544)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.384( 0.125)\tLoss 7.1481e-01(1.4278e+00)\tAcc@1 81.250(60.246)\tAcc@5 93.750(92.725)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.029( 0.121)\tLoss 8.5470e-01(1.3307e+00)\tAcc@1 68.750(61.708)\tAcc@5 100.000(93.574)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.362( 0.123)\tLoss 2.4591e+00(1.3356e+00)\tAcc@1 43.750(62.269)\tAcc@5 68.750(92.670)\tAcc@10 93.750(99.151)\n",
      "Test:[ 90/111]\tTime  0.055( 0.121)\tLoss 4.4773e-01(1.3050e+00)\tAcc@1 81.250(61.951)\tAcc@5 100.000(93.132)\tAcc@10 100.000(99.245)\n",
      "Test:[100/111]\tTime  0.362( 0.121)\tLoss 6.3775e-01(1.2324e+00)\tAcc@1 68.750(63.304)\tAcc@5 100.000(93.812)\tAcc@10 100.000(99.319)\n",
      "Test:[110/111]\tTime  0.040( 0.119)\tLoss 1.4925e+00(1.2559e+00)\tAcc@1 60.000(62.704)\tAcc@5 86.667(93.521)\tAcc@10 100.000(99.380)\n",
      " * Acc@1 62.704 Acc@5 93.521 Acc@10 99.380\n",
      "==> Epoch 18/50\n",
      "Train batch 10/114\t Loss 0.198928 (0.263242)\n",
      "Train batch 20/114\t Loss 0.167865 (0.233085)\n",
      "Train batch 30/114\t Loss 0.169026 (0.225479)\n",
      "Train batch 40/114\t Loss 0.254640 (0.220677)\n",
      "Train batch 50/114\t Loss 0.110956 (0.226657)\n",
      "Train batch 60/114\t Loss 0.175169 (0.218901)\n",
      "Train batch 70/114\t Loss 0.089442 (0.214441)\n",
      "Train batch 80/114\t Loss 0.105830 (0.209418)\n",
      "Train batch 90/114\t Loss 0.143035 (0.206113)\n",
      "Train batch 100/114\t Loss 0.216133 (0.207807)\n",
      "Train batch 110/114\t Loss 0.062147 (0.204622)\n",
      "Test:[  0/111]\tTime  0.647( 0.647)\tLoss 1.3159e+00(1.3159e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.015( 0.148)\tLoss 4.5714e-01(9.7710e-01)\tAcc@1 81.250(71.591)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.383( 0.140)\tLoss 7.0929e-01(9.6727e-01)\tAcc@1 81.250(68.750)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.014( 0.127)\tLoss 6.5574e-01(1.3064e+00)\tAcc@1 75.000(63.306)\tAcc@5 100.000(94.960)\tAcc@10 100.000(99.194)\n",
      "Test:[ 40/111]\tTime  0.352( 0.127)\tLoss 2.5349e+00(1.4116e+00)\tAcc@1 43.750(61.128)\tAcc@5 81.250(93.140)\tAcc@10 93.750(98.476)\n",
      "Test:[ 50/111]\tTime  0.015( 0.122)\tLoss 1.5246e+00(1.4370e+00)\tAcc@1 56.250(61.397)\tAcc@5 93.750(92.770)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.368( 0.123)\tLoss 7.1883e-01(1.3972e+00)\tAcc@1 75.000(61.988)\tAcc@5 93.750(93.648)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.015( 0.119)\tLoss 8.8974e-01(1.3015e+00)\tAcc@1 68.750(63.292)\tAcc@5 100.000(94.454)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.341( 0.120)\tLoss 2.3763e+00(1.3053e+00)\tAcc@1 50.000(63.735)\tAcc@5 68.750(93.519)\tAcc@10 93.750(99.151)\n",
      "Test:[ 90/111]\tTime  0.014( 0.118)\tLoss 4.0227e-01(1.2678e+00)\tAcc@1 81.250(63.599)\tAcc@5 100.000(93.956)\tAcc@10 100.000(99.245)\n",
      "Test:[100/111]\tTime  0.329( 0.119)\tLoss 6.6639e-01(1.1973e+00)\tAcc@1 75.000(65.347)\tAcc@5 100.000(94.554)\tAcc@10 100.000(99.319)\n",
      "Test:[110/111]\tTime  0.013( 0.117)\tLoss 1.4747e+00(1.2208e+00)\tAcc@1 66.667(64.676)\tAcc@5 86.667(94.197)\tAcc@10 100.000(99.380)\n",
      " * Acc@1 64.676 Acc@5 94.197 Acc@10 99.380\n",
      "==> Epoch 19/50\n",
      "Train batch 10/114\t Loss 0.125760 (0.160607)\n",
      "Train batch 20/114\t Loss 0.262395 (0.195726)\n",
      "Train batch 30/114\t Loss 0.258997 (0.192149)\n",
      "Train batch 40/114\t Loss 0.150547 (0.188559)\n",
      "Train batch 50/114\t Loss 0.180229 (0.192989)\n",
      "Train batch 60/114\t Loss 0.169403 (0.191317)\n",
      "Train batch 70/114\t Loss 0.394082 (0.190088)\n",
      "Train batch 80/114\t Loss 0.088176 (0.193539)\n",
      "Train batch 90/114\t Loss 0.149900 (0.197137)\n",
      "Train batch 100/114\t Loss 0.164484 (0.197768)\n",
      "Train batch 110/114\t Loss 0.216295 (0.196516)\n",
      "Test:[  0/111]\tTime  0.651( 0.651)\tLoss 1.1941e+00(1.1941e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.045( 0.150)\tLoss 4.6835e-01(9.3244e-01)\tAcc@1 81.250(71.023)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.365( 0.141)\tLoss 7.2637e-01(9.4043e-01)\tAcc@1 68.750(67.560)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.033( 0.127)\tLoss 6.6466e-01(1.2840e+00)\tAcc@1 68.750(60.887)\tAcc@5 100.000(94.355)\tAcc@10 100.000(99.194)\n",
      "Test:[ 40/111]\tTime  0.415( 0.129)\tLoss 2.5397e+00(1.3960e+00)\tAcc@1 37.500(58.841)\tAcc@5 81.250(92.530)\tAcc@10 100.000(98.780)\n",
      "Test:[ 50/111]\tTime  0.017( 0.122)\tLoss 1.3695e+00(1.4150e+00)\tAcc@1 62.500(59.436)\tAcc@5 100.000(92.402)\tAcc@10 100.000(99.020)\n",
      "Test:[ 60/111]\tTime  0.411( 0.124)\tLoss 7.5571e-01(1.3727e+00)\tAcc@1 81.250(60.451)\tAcc@5 93.750(93.340)\tAcc@10 100.000(99.180)\n",
      "Test:[ 70/111]\tTime  0.025( 0.120)\tLoss 9.9689e-01(1.2808e+00)\tAcc@1 62.500(61.972)\tAcc@5 100.000(94.278)\tAcc@10 100.000(99.296)\n",
      "Test:[ 80/111]\tTime  0.362( 0.121)\tLoss 2.4470e+00(1.2883e+00)\tAcc@1 43.750(62.577)\tAcc@5 75.000(93.519)\tAcc@10 93.750(99.306)\n",
      "Test:[ 90/111]\tTime  0.045( 0.118)\tLoss 4.2735e-01(1.2558e+00)\tAcc@1 81.250(62.431)\tAcc@5 100.000(93.956)\tAcc@10 100.000(99.382)\n",
      "Test:[100/111]\tTime  0.365( 0.119)\tLoss 6.2094e-01(1.1859e+00)\tAcc@1 68.750(63.923)\tAcc@5 100.000(94.554)\tAcc@10 100.000(99.443)\n",
      "Test:[110/111]\tTime  0.014( 0.117)\tLoss 1.6183e+00(1.2200e+00)\tAcc@1 60.000(63.155)\tAcc@5 86.667(94.141)\tAcc@10 100.000(99.437)\n",
      " * Acc@1 63.155 Acc@5 94.141 Acc@10 99.437\n",
      "==> Epoch 20/50\n",
      "Train batch 10/114\t Loss 0.330011 (0.221597)\n",
      "Train batch 20/114\t Loss 0.321634 (0.205817)\n",
      "Train batch 30/114\t Loss 0.234290 (0.219026)\n",
      "Train batch 40/114\t Loss 0.188655 (0.209139)\n",
      "Train batch 50/114\t Loss 0.188104 (0.211168)\n",
      "Train batch 60/114\t Loss 0.285578 (0.210737)\n",
      "Train batch 70/114\t Loss 0.100521 (0.213469)\n",
      "Train batch 80/114\t Loss 0.090954 (0.212052)\n",
      "Train batch 90/114\t Loss 0.210200 (0.210865)\n",
      "Train batch 100/114\t Loss 0.158881 (0.206319)\n",
      "Train batch 110/114\t Loss 0.168444 (0.202781)\n",
      "Test:[  0/111]\tTime  0.655( 0.655)\tLoss 1.2845e+00(1.2845e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.041( 0.147)\tLoss 5.6905e-01(9.7898e-01)\tAcc@1 81.250(70.455)\tAcc@5 100.000(96.023)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.397( 0.140)\tLoss 7.8651e-01(9.6816e-01)\tAcc@1 75.000(69.345)\tAcc@5 100.000(97.619)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.016( 0.126)\tLoss 6.3695e-01(1.2931e+00)\tAcc@1 75.000(63.306)\tAcc@5 100.000(95.766)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.404( 0.128)\tLoss 2.5881e+00(1.4179e+00)\tAcc@1 43.750(60.518)\tAcc@5 75.000(93.293)\tAcc@10 93.750(98.171)\n",
      "Test:[ 50/111]\tTime  0.014( 0.122)\tLoss 1.4284e+00(1.4502e+00)\tAcc@1 68.750(60.539)\tAcc@5 93.750(93.015)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.371( 0.123)\tLoss 7.5312e-01(1.3955e+00)\tAcc@1 75.000(61.373)\tAcc@5 93.750(93.852)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.018( 0.120)\tLoss 9.0170e-01(1.3012e+00)\tAcc@1 62.500(62.764)\tAcc@5 100.000(94.630)\tAcc@10 100.000(98.944)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 80/111]\tTime  0.384( 0.121)\tLoss 2.5004e+00(1.3097e+00)\tAcc@1 43.750(63.040)\tAcc@5 81.250(93.827)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.019( 0.118)\tLoss 4.9411e-01(1.2741e+00)\tAcc@1 81.250(62.843)\tAcc@5 100.000(94.162)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.371( 0.119)\tLoss 6.2209e-01(1.2087e+00)\tAcc@1 75.000(64.295)\tAcc@5 100.000(94.740)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.013( 0.117)\tLoss 1.5072e+00(1.2352e+00)\tAcc@1 66.667(63.662)\tAcc@5 86.667(94.535)\tAcc@10 100.000(99.211)\n",
      " * Acc@1 63.662 Acc@5 94.535 Acc@10 99.211\n",
      "==> Epoch 21/50\n",
      "Train batch 10/114\t Loss 0.211986 (0.185086)\n",
      "Train batch 20/114\t Loss 0.115414 (0.177062)\n",
      "Train batch 30/114\t Loss 0.217329 (0.189812)\n",
      "Train batch 40/114\t Loss 0.270748 (0.182105)\n",
      "Train batch 50/114\t Loss 0.183357 (0.184594)\n",
      "Train batch 60/114\t Loss 0.241258 (0.185727)\n",
      "Train batch 70/114\t Loss 0.189326 (0.186376)\n",
      "Train batch 80/114\t Loss 0.247384 (0.189675)\n",
      "Train batch 90/114\t Loss 0.180496 (0.193279)\n",
      "Train batch 100/114\t Loss 0.151853 (0.185810)\n",
      "Train batch 110/114\t Loss 0.344557 (0.186707)\n",
      "Test:[  0/111]\tTime  0.674( 0.674)\tLoss 1.2420e+00(1.2420e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.017( 0.150)\tLoss 5.1711e-01(9.4866e-01)\tAcc@1 81.250(71.591)\tAcc@5 100.000(94.886)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.375( 0.143)\tLoss 7.5906e-01(9.3766e-01)\tAcc@1 75.000(69.345)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.014( 0.129)\tLoss 6.5292e-01(1.2679e+00)\tAcc@1 75.000(63.710)\tAcc@5 100.000(94.960)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.346( 0.129)\tLoss 2.4957e+00(1.3861e+00)\tAcc@1 37.500(61.128)\tAcc@5 81.250(92.988)\tAcc@10 93.750(98.476)\n",
      "Test:[ 50/111]\tTime  0.016( 0.123)\tLoss 1.3217e+00(1.4122e+00)\tAcc@1 68.750(61.397)\tAcc@5 93.750(92.892)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.513( 0.126)\tLoss 7.7308e-01(1.3792e+00)\tAcc@1 81.250(62.295)\tAcc@5 93.750(93.750)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.020( 0.124)\tLoss 1.0839e+00(1.2897e+00)\tAcc@1 56.250(63.292)\tAcc@5 100.000(94.630)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.253( 0.124)\tLoss 2.4962e+00(1.3010e+00)\tAcc@1 50.000(63.426)\tAcc@5 75.000(93.750)\tAcc@10 93.750(99.151)\n",
      "Test:[ 90/111]\tTime  0.015( 0.124)\tLoss 4.7688e-01(1.2737e+00)\tAcc@1 81.250(63.049)\tAcc@5 100.000(94.093)\tAcc@10 100.000(99.245)\n",
      "Test:[100/111]\tTime  0.228( 0.123)\tLoss 6.5366e-01(1.2061e+00)\tAcc@1 62.500(64.480)\tAcc@5 100.000(94.678)\tAcc@10 100.000(99.319)\n",
      "Test:[110/111]\tTime  0.013( 0.122)\tLoss 1.6088e+00(1.2378e+00)\tAcc@1 60.000(63.662)\tAcc@5 86.667(94.310)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 63.662 Acc@5 94.310 Acc@10 99.324\n",
      "==> Epoch 22/50\n",
      "Train batch 10/114\t Loss 0.417418 (0.186104)\n",
      "Train batch 20/114\t Loss 0.406439 (0.201084)\n",
      "Train batch 30/114\t Loss 0.218933 (0.194790)\n",
      "Train batch 40/114\t Loss 0.094090 (0.196393)\n",
      "Train batch 50/114\t Loss 0.316225 (0.190631)\n",
      "Train batch 60/114\t Loss 0.086814 (0.183656)\n",
      "Train batch 70/114\t Loss 0.153370 (0.182427)\n",
      "Train batch 80/114\t Loss 0.161893 (0.185147)\n",
      "Train batch 90/114\t Loss 0.119625 (0.183603)\n",
      "Train batch 100/114\t Loss 0.184907 (0.181953)\n",
      "Train batch 110/114\t Loss 0.141204 (0.186419)\n",
      "Test:[  0/111]\tTime  0.697( 0.697)\tLoss 1.2272e+00(1.2272e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.017( 0.168)\tLoss 5.4975e-01(9.4618e-01)\tAcc@1 81.250(73.295)\tAcc@5 100.000(94.318)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.325( 0.157)\tLoss 7.8784e-01(9.6930e-01)\tAcc@1 75.000(69.940)\tAcc@5 100.000(96.429)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.149( 0.144)\tLoss 7.4598e-01(1.2975e+00)\tAcc@1 68.750(64.113)\tAcc@5 100.000(94.556)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.368( 0.142)\tLoss 2.5507e+00(1.4187e+00)\tAcc@1 37.500(61.280)\tAcc@5 75.000(92.226)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.017( 0.137)\tLoss 1.4407e+00(1.4551e+00)\tAcc@1 62.500(60.907)\tAcc@5 93.750(92.157)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.394( 0.137)\tLoss 7.6110e-01(1.4196e+00)\tAcc@1 75.000(61.475)\tAcc@5 93.750(93.135)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.014( 0.132)\tLoss 1.0034e+00(1.3250e+00)\tAcc@1 68.750(63.204)\tAcc@5 100.000(94.014)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.349( 0.131)\tLoss 2.5458e+00(1.3337e+00)\tAcc@1 43.750(63.426)\tAcc@5 75.000(93.364)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.014( 0.128)\tLoss 5.3545e-01(1.3028e+00)\tAcc@1 81.250(63.393)\tAcc@5 100.000(93.750)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.128( 0.128)\tLoss 6.3283e-01(1.2339e+00)\tAcc@1 68.750(64.728)\tAcc@5 100.000(94.369)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.014( 0.127)\tLoss 1.6743e+00(1.2609e+00)\tAcc@1 46.667(63.831)\tAcc@5 86.667(94.085)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 63.831 Acc@5 94.085 Acc@10 99.324\n",
      "==> Epoch 23/50\n",
      "Train batch 10/114\t Loss 0.382546 (0.218148)\n",
      "Train batch 20/114\t Loss 0.296228 (0.204165)\n",
      "Train batch 30/114\t Loss 0.207468 (0.191342)\n",
      "Train batch 40/114\t Loss 0.112688 (0.188056)\n",
      "Train batch 50/114\t Loss 0.107430 (0.177821)\n",
      "Train batch 60/114\t Loss 0.194853 (0.177663)\n",
      "Train batch 70/114\t Loss 0.197263 (0.177841)\n",
      "Train batch 80/114\t Loss 0.193229 (0.177758)\n",
      "Train batch 90/114\t Loss 0.151156 (0.179331)\n",
      "Train batch 100/114\t Loss 0.180650 (0.177292)\n",
      "Train batch 110/114\t Loss 0.170607 (0.177738)\n",
      "Test:[  0/111]\tTime  0.672( 0.672)\tLoss 1.3032e+00(1.3032e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.047( 0.150)\tLoss 5.8639e-01(9.7594e-01)\tAcc@1 81.250(72.727)\tAcc@5 100.000(94.886)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.436( 0.144)\tLoss 7.8947e-01(9.7412e-01)\tAcc@1 68.750(69.345)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.017( 0.128)\tLoss 6.7633e-01(1.3012e+00)\tAcc@1 75.000(64.113)\tAcc@5 100.000(95.161)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.408( 0.130)\tLoss 2.6031e+00(1.4209e+00)\tAcc@1 37.500(61.128)\tAcc@5 75.000(92.683)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.023( 0.124)\tLoss 1.4511e+00(1.4595e+00)\tAcc@1 68.750(61.029)\tAcc@5 93.750(92.402)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.420( 0.126)\tLoss 6.9982e-01(1.4121e+00)\tAcc@1 75.000(61.475)\tAcc@5 100.000(93.545)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.014( 0.122)\tLoss 8.9389e-01(1.3139e+00)\tAcc@1 68.750(63.116)\tAcc@5 100.000(94.366)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.409( 0.123)\tLoss 2.5102e+00(1.3226e+00)\tAcc@1 43.750(63.503)\tAcc@5 75.000(93.519)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.015( 0.120)\tLoss 4.6571e-01(1.2900e+00)\tAcc@1 81.250(63.187)\tAcc@5 100.000(93.887)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.399( 0.122)\tLoss 6.7286e-01(1.2225e+00)\tAcc@1 62.500(64.480)\tAcc@5 100.000(94.431)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.013( 0.119)\tLoss 1.5898e+00(1.2474e+00)\tAcc@1 53.333(63.549)\tAcc@5 86.667(94.141)\tAcc@10 100.000(99.268)\n",
      " * Acc@1 63.549 Acc@5 94.141 Acc@10 99.268\n",
      "==> Epoch 24/50\n",
      "Train batch 10/114\t Loss 0.153997 (0.150639)\n",
      "Train batch 20/114\t Loss 0.185831 (0.178369)\n",
      "Train batch 30/114\t Loss 0.152176 (0.178228)\n",
      "Train batch 40/114\t Loss 0.146195 (0.187464)\n",
      "Train batch 50/114\t Loss 0.087714 (0.183235)\n",
      "Train batch 60/114\t Loss 0.227161 (0.184675)\n",
      "Train batch 70/114\t Loss 0.138991 (0.184338)\n",
      "Train batch 80/114\t Loss 0.276226 (0.186232)\n",
      "Train batch 90/114\t Loss 0.073811 (0.181591)\n",
      "Train batch 100/114\t Loss 0.199275 (0.177917)\n",
      "Train batch 110/114\t Loss 0.076514 (0.174523)\n",
      "Test:[  0/111]\tTime  0.777( 0.777)\tLoss 1.2517e+00(1.2517e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.014( 0.179)\tLoss 5.4450e-01(9.4842e-01)\tAcc@1 81.250(71.023)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.406( 0.167)\tLoss 7.5361e-01(9.6388e-01)\tAcc@1 75.000(67.857)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.014( 0.143)\tLoss 6.0429e-01(1.2779e+00)\tAcc@1 75.000(62.298)\tAcc@5 100.000(95.363)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.409( 0.141)\tLoss 2.5825e+00(1.3913e+00)\tAcc@1 37.500(59.604)\tAcc@5 81.250(93.445)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.014( 0.132)\tLoss 1.4728e+00(1.4157e+00)\tAcc@1 62.500(60.294)\tAcc@5 93.750(93.137)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.420( 0.132)\tLoss 7.3712e-01(1.3658e+00)\tAcc@1 75.000(60.861)\tAcc@5 93.750(93.955)\tAcc@10 100.000(98.770)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 70/111]\tTime  0.017( 0.127)\tLoss 8.9900e-01(1.2737e+00)\tAcc@1 68.750(62.500)\tAcc@5 100.000(94.718)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.394( 0.128)\tLoss 2.5302e+00(1.2795e+00)\tAcc@1 37.500(63.040)\tAcc@5 81.250(93.904)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.014( 0.124)\tLoss 4.5611e-01(1.2466e+00)\tAcc@1 81.250(62.843)\tAcc@5 100.000(94.231)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.399( 0.125)\tLoss 6.4530e-01(1.1805e+00)\tAcc@1 68.750(64.171)\tAcc@5 100.000(94.802)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.013( 0.122)\tLoss 1.4775e+00(1.2061e+00)\tAcc@1 60.000(63.380)\tAcc@5 86.667(94.479)\tAcc@10 100.000(99.211)\n",
      " * Acc@1 63.380 Acc@5 94.479 Acc@10 99.211\n",
      "==> Epoch 25/50\n",
      "Train batch 10/114\t Loss 0.105745 (0.121474)\n",
      "Train batch 20/114\t Loss 0.250109 (0.150112)\n",
      "Train batch 30/114\t Loss 0.080771 (0.145918)\n",
      "Train batch 40/114\t Loss 0.166319 (0.157064)\n",
      "Train batch 50/114\t Loss 0.332277 (0.169209)\n",
      "Train batch 60/114\t Loss 0.128932 (0.168506)\n",
      "Train batch 70/114\t Loss 0.225678 (0.170097)\n",
      "Train batch 80/114\t Loss 0.081822 (0.167923)\n",
      "Train batch 90/114\t Loss 0.155946 (0.167625)\n",
      "Train batch 100/114\t Loss 0.119717 (0.167621)\n",
      "Train batch 110/114\t Loss 0.198839 (0.170752)\n",
      "Test:[  0/111]\tTime  0.653( 0.653)\tLoss 1.3198e+00(1.3198e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.067( 0.153)\tLoss 5.9617e-01(9.9455e-01)\tAcc@1 81.250(70.455)\tAcc@5 100.000(94.318)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.335( 0.145)\tLoss 8.1463e-01(9.8422e-01)\tAcc@1 62.500(68.155)\tAcc@5 100.000(96.726)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.094( 0.131)\tLoss 7.0146e-01(1.3172e+00)\tAcc@1 81.250(63.306)\tAcc@5 100.000(94.758)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.329( 0.130)\tLoss 2.5784e+00(1.4411e+00)\tAcc@1 37.500(60.671)\tAcc@5 81.250(92.530)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.069( 0.124)\tLoss 1.5248e+00(1.4779e+00)\tAcc@1 62.500(60.662)\tAcc@5 93.750(92.402)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.364( 0.124)\tLoss 6.7222e-01(1.4163e+00)\tAcc@1 75.000(61.373)\tAcc@5 100.000(93.545)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.017( 0.120)\tLoss 9.0462e-01(1.3163e+00)\tAcc@1 68.750(63.292)\tAcc@5 100.000(94.366)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.370( 0.122)\tLoss 2.5610e+00(1.3285e+00)\tAcc@1 43.750(63.426)\tAcc@5 75.000(93.596)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.028( 0.119)\tLoss 4.4554e-01(1.3002e+00)\tAcc@1 81.250(63.049)\tAcc@5 100.000(93.956)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.400( 0.121)\tLoss 6.4457e-01(1.2300e+00)\tAcc@1 75.000(64.542)\tAcc@5 100.000(94.554)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.015( 0.118)\tLoss 1.5370e+00(1.2535e+00)\tAcc@1 53.333(63.493)\tAcc@5 86.667(94.310)\tAcc@10 100.000(99.268)\n",
      " * Acc@1 63.493 Acc@5 94.310 Acc@10 99.268\n",
      "==> Epoch 26/50\n",
      "Train batch 10/114\t Loss 0.203444 (0.172830)\n",
      "Train batch 20/114\t Loss 0.138223 (0.179322)\n",
      "Train batch 30/114\t Loss 0.152516 (0.176681)\n",
      "Train batch 40/114\t Loss 0.192658 (0.170871)\n",
      "Train batch 50/114\t Loss 0.252760 (0.172395)\n",
      "Train batch 60/114\t Loss 0.207846 (0.171566)\n",
      "Train batch 70/114\t Loss 0.226255 (0.174763)\n",
      "Train batch 80/114\t Loss 0.201534 (0.171838)\n",
      "Train batch 90/114\t Loss 0.104610 (0.170774)\n",
      "Train batch 100/114\t Loss 0.066261 (0.172768)\n",
      "Train batch 110/114\t Loss 0.231757 (0.170839)\n",
      "Test:[  0/111]\tTime  0.666( 0.666)\tLoss 1.2782e+00(1.2782e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.015( 0.153)\tLoss 5.7967e-01(9.6364e-01)\tAcc@1 81.250(71.591)\tAcc@5 100.000(94.886)\tAcc@10 100.000(98.295)\n",
      "Test:[ 20/111]\tTime  0.359( 0.142)\tLoss 7.7977e-01(9.7063e-01)\tAcc@1 68.750(69.048)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.107)\n",
      "Test:[ 30/111]\tTime  0.020( 0.131)\tLoss 6.7146e-01(1.2933e+00)\tAcc@1 75.000(63.710)\tAcc@5 100.000(95.161)\tAcc@10 100.000(98.589)\n",
      "Test:[ 40/111]\tTime  0.295( 0.129)\tLoss 2.5332e+00(1.4093e+00)\tAcc@1 37.500(60.976)\tAcc@5 81.250(92.683)\tAcc@10 93.750(98.018)\n",
      "Test:[ 50/111]\tTime  0.015( 0.125)\tLoss 1.4741e+00(1.4468e+00)\tAcc@1 62.500(61.275)\tAcc@5 93.750(92.402)\tAcc@10 100.000(98.407)\n",
      "Test:[ 60/111]\tTime  0.273( 0.124)\tLoss 7.1810e-01(1.3978e+00)\tAcc@1 75.000(61.783)\tAcc@5 100.000(93.443)\tAcc@10 100.000(98.668)\n",
      "Test:[ 70/111]\tTime  0.016( 0.122)\tLoss 9.7138e-01(1.3031e+00)\tAcc@1 62.500(63.292)\tAcc@5 100.000(94.278)\tAcc@10 100.000(98.856)\n",
      "Test:[ 80/111]\tTime  0.221( 0.121)\tLoss 2.5272e+00(1.3121e+00)\tAcc@1 43.750(63.657)\tAcc@5 68.750(93.364)\tAcc@10 93.750(98.920)\n",
      "Test:[ 90/111]\tTime  0.015( 0.120)\tLoss 4.5125e-01(1.2795e+00)\tAcc@1 81.250(63.187)\tAcc@5 100.000(93.750)\tAcc@10 100.000(99.038)\n",
      "Test:[100/111]\tTime  0.195( 0.120)\tLoss 6.5301e-01(1.2092e+00)\tAcc@1 68.750(64.604)\tAcc@5 100.000(94.369)\tAcc@10 100.000(99.134)\n",
      "Test:[110/111]\tTime  0.014( 0.119)\tLoss 1.5429e+00(1.2345e+00)\tAcc@1 66.667(63.887)\tAcc@5 86.667(94.085)\tAcc@10 100.000(99.211)\n",
      " * Acc@1 63.887 Acc@5 94.085 Acc@10 99.211\n",
      "==> Epoch 27/50\n",
      "Train batch 10/114\t Loss 0.417360 (0.175007)\n",
      "Train batch 20/114\t Loss 0.262884 (0.159642)\n",
      "Train batch 30/114\t Loss 0.216208 (0.168348)\n",
      "Train batch 40/114\t Loss 0.144555 (0.166972)\n",
      "Train batch 50/114\t Loss 0.185417 (0.171642)\n",
      "Train batch 60/114\t Loss 0.264808 (0.170750)\n",
      "Train batch 70/114\t Loss 0.104292 (0.170019)\n",
      "Train batch 80/114\t Loss 0.145785 (0.170629)\n",
      "Train batch 90/114\t Loss 0.165653 (0.174555)\n",
      "Train batch 100/114\t Loss 0.199938 (0.174900)\n",
      "Train batch 110/114\t Loss 0.175738 (0.174772)\n",
      "Test:[  0/111]\tTime  0.671( 0.671)\tLoss 1.2506e+00(1.2506e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.028( 0.151)\tLoss 5.4491e-01(9.3271e-01)\tAcc@1 81.250(73.295)\tAcc@5 100.000(94.886)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.369( 0.142)\tLoss 7.5039e-01(9.4716e-01)\tAcc@1 81.250(70.833)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.018( 0.128)\tLoss 6.4201e-01(1.2828e+00)\tAcc@1 75.000(65.121)\tAcc@5 100.000(94.960)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.370( 0.129)\tLoss 2.6510e+00(1.4031e+00)\tAcc@1 43.750(62.500)\tAcc@5 75.000(92.835)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.015( 0.122)\tLoss 1.4225e+00(1.4366e+00)\tAcc@1 62.500(62.500)\tAcc@5 93.750(92.647)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.392( 0.124)\tLoss 7.1624e-01(1.3979e+00)\tAcc@1 75.000(62.602)\tAcc@5 93.750(93.545)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.015( 0.120)\tLoss 9.5410e-01(1.3031e+00)\tAcc@1 62.500(63.996)\tAcc@5 100.000(94.366)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.378( 0.121)\tLoss 2.4714e+00(1.3097e+00)\tAcc@1 50.000(64.275)\tAcc@5 81.250(93.596)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.016( 0.118)\tLoss 4.5804e-01(1.2754e+00)\tAcc@1 81.250(63.874)\tAcc@5 100.000(93.956)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.378( 0.120)\tLoss 6.3802e-01(1.2057e+00)\tAcc@1 68.750(65.223)\tAcc@5 100.000(94.554)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.013( 0.117)\tLoss 1.5487e+00(1.2322e+00)\tAcc@1 60.000(64.338)\tAcc@5 86.667(94.197)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.338 Acc@5 94.197 Acc@10 99.324\n",
      "==> Epoch 28/50\n",
      "Train batch 10/114\t Loss 0.217524 (0.167184)\n",
      "Train batch 20/114\t Loss 0.137102 (0.166200)\n",
      "Train batch 30/114\t Loss 0.200692 (0.173523)\n",
      "Train batch 40/114\t Loss 0.136174 (0.168353)\n",
      "Train batch 50/114\t Loss 0.140117 (0.173084)\n",
      "Train batch 60/114\t Loss 0.167253 (0.175239)\n",
      "Train batch 70/114\t Loss 0.177358 (0.177391)\n",
      "Train batch 80/114\t Loss 0.186702 (0.182282)\n",
      "Train batch 90/114\t Loss 0.085480 (0.180454)\n",
      "Train batch 100/114\t Loss 0.181281 (0.179952)\n",
      "Train batch 110/114\t Loss 0.350303 (0.181564)\n",
      "Test:[  0/111]\tTime  0.680( 0.680)\tLoss 1.2520e+00(1.2520e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.045( 0.154)\tLoss 5.5045e-01(9.5622e-01)\tAcc@1 81.250(69.886)\tAcc@5 100.000(96.023)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.436( 0.148)\tLoss 7.3589e-01(9.6606e-01)\tAcc@1 68.750(66.667)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.015( 0.133)\tLoss 6.6800e-01(1.2766e+00)\tAcc@1 75.000(61.895)\tAcc@5 100.000(95.363)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.369( 0.133)\tLoss 2.5527e+00(1.3999e+00)\tAcc@1 37.500(59.604)\tAcc@5 81.250(93.293)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.014( 0.127)\tLoss 1.4857e+00(1.4405e+00)\tAcc@1 62.500(59.804)\tAcc@5 87.500(93.015)\tAcc@10 100.000(98.529)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 60/111]\tTime  0.422( 0.128)\tLoss 7.3339e-01(1.3768e+00)\tAcc@1 68.750(60.553)\tAcc@5 93.750(93.852)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.014( 0.123)\tLoss 7.6847e-01(1.2788e+00)\tAcc@1 75.000(62.588)\tAcc@5 100.000(94.630)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.395( 0.123)\tLoss 2.4837e+00(1.2852e+00)\tAcc@1 37.500(63.194)\tAcc@5 68.750(93.750)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.018( 0.121)\tLoss 4.5636e-01(1.2558e+00)\tAcc@1 81.250(62.706)\tAcc@5 100.000(94.093)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.402( 0.123)\tLoss 6.0364e-01(1.1893e+00)\tAcc@1 68.750(64.047)\tAcc@5 100.000(94.678)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.018( 0.120)\tLoss 1.4708e+00(1.2086e+00)\tAcc@1 66.667(63.493)\tAcc@5 86.667(94.366)\tAcc@10 100.000(99.211)\n",
      " * Acc@1 63.493 Acc@5 94.366 Acc@10 99.211\n",
      "==> Epoch 29/50\n",
      "Train batch 10/114\t Loss 0.067865 (0.186762)\n",
      "Train batch 20/114\t Loss 0.304568 (0.181164)\n",
      "Train batch 30/114\t Loss 0.233529 (0.190080)\n",
      "Train batch 40/114\t Loss 0.152253 (0.191335)\n",
      "Train batch 50/114\t Loss 0.193735 (0.188528)\n",
      "Train batch 60/114\t Loss 0.292445 (0.183693)\n",
      "Train batch 70/114\t Loss 0.099758 (0.180688)\n",
      "Train batch 80/114\t Loss 0.130352 (0.177547)\n",
      "Train batch 90/114\t Loss 0.111233 (0.178648)\n",
      "Train batch 100/114\t Loss 0.227022 (0.177978)\n",
      "Train batch 110/114\t Loss 0.121098 (0.173751)\n",
      "Test:[  0/111]\tTime  0.660( 0.660)\tLoss 1.2856e+00(1.2856e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.016( 0.150)\tLoss 5.5991e-01(9.6273e-01)\tAcc@1 81.250(71.591)\tAcc@5 100.000(94.886)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.477( 0.149)\tLoss 7.9267e-01(9.6821e-01)\tAcc@1 68.750(68.452)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.015( 0.139)\tLoss 6.9638e-01(1.2921e+00)\tAcc@1 81.250(63.710)\tAcc@5 100.000(94.758)\tAcc@10 100.000(98.589)\n",
      "Test:[ 40/111]\tTime  0.417( 0.145)\tLoss 2.4877e+00(1.4097e+00)\tAcc@1 37.500(60.823)\tAcc@5 81.250(92.530)\tAcc@10 93.750(98.018)\n",
      "Test:[ 50/111]\tTime  0.019( 0.137)\tLoss 1.4825e+00(1.4406e+00)\tAcc@1 62.500(60.907)\tAcc@5 87.500(92.279)\tAcc@10 100.000(98.407)\n",
      "Test:[ 60/111]\tTime  0.439( 0.137)\tLoss 6.5611e-01(1.3906e+00)\tAcc@1 81.250(61.270)\tAcc@5 100.000(93.443)\tAcc@10 100.000(98.668)\n",
      "Test:[ 70/111]\tTime  0.019( 0.132)\tLoss 9.0655e-01(1.2927e+00)\tAcc@1 68.750(63.028)\tAcc@5 100.000(94.278)\tAcc@10 100.000(98.856)\n",
      "Test:[ 80/111]\tTime  0.407( 0.133)\tLoss 2.5411e+00(1.3057e+00)\tAcc@1 43.750(63.272)\tAcc@5 75.000(93.519)\tAcc@10 93.750(98.920)\n",
      "Test:[ 90/111]\tTime  0.019( 0.129)\tLoss 4.3836e-01(1.2778e+00)\tAcc@1 81.250(63.049)\tAcc@5 100.000(93.819)\tAcc@10 100.000(99.038)\n",
      "Test:[100/111]\tTime  0.505( 0.131)\tLoss 6.8397e-01(1.2109e+00)\tAcc@1 62.500(64.418)\tAcc@5 100.000(94.369)\tAcc@10 100.000(99.134)\n",
      "Test:[110/111]\tTime  0.017( 0.129)\tLoss 1.5218e+00(1.2348e+00)\tAcc@1 53.333(63.718)\tAcc@5 86.667(94.141)\tAcc@10 100.000(99.211)\n",
      " * Acc@1 63.718 Acc@5 94.141 Acc@10 99.211\n",
      "==> Epoch 30/50\n",
      "Train batch 10/114\t Loss 0.110897 (0.151983)\n",
      "Train batch 20/114\t Loss 0.267590 (0.183827)\n",
      "Train batch 30/114\t Loss 0.084731 (0.167668)\n",
      "Train batch 40/114\t Loss 0.128172 (0.171137)\n",
      "Train batch 50/114\t Loss 0.065850 (0.170040)\n",
      "Train batch 60/114\t Loss 0.184014 (0.169759)\n",
      "Train batch 70/114\t Loss 0.089242 (0.167452)\n",
      "Train batch 80/114\t Loss 0.157554 (0.169505)\n",
      "Train batch 90/114\t Loss 0.172563 (0.171522)\n",
      "Train batch 100/114\t Loss 0.095738 (0.172148)\n",
      "Train batch 110/114\t Loss 0.122494 (0.172447)\n",
      "Test:[  0/111]\tTime  0.673( 0.673)\tLoss 1.1813e+00(1.1813e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.018( 0.153)\tLoss 5.3794e-01(8.8175e-01)\tAcc@1 81.250(74.432)\tAcc@5 100.000(96.023)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.438( 0.146)\tLoss 7.5854e-01(9.0165e-01)\tAcc@1 75.000(70.833)\tAcc@5 100.000(97.619)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.015( 0.130)\tLoss 5.7438e-01(1.2079e+00)\tAcc@1 75.000(64.919)\tAcc@5 100.000(95.565)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.423( 0.132)\tLoss 2.5178e+00(1.3253e+00)\tAcc@1 43.750(62.195)\tAcc@5 81.250(93.293)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.019( 0.126)\tLoss 1.3797e+00(1.3585e+00)\tAcc@1 68.750(62.255)\tAcc@5 93.750(93.137)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.409( 0.127)\tLoss 7.3120e-01(1.3116e+00)\tAcc@1 81.250(62.398)\tAcc@5 93.750(93.955)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.016( 0.122)\tLoss 8.3981e-01(1.2222e+00)\tAcc@1 62.500(64.173)\tAcc@5 100.000(94.806)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.409( 0.123)\tLoss 2.4947e+00(1.2343e+00)\tAcc@1 43.750(64.506)\tAcc@5 81.250(94.059)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.093( 0.122)\tLoss 4.7680e-01(1.2047e+00)\tAcc@1 81.250(64.217)\tAcc@5 100.000(94.368)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.374( 0.125)\tLoss 5.9318e-01(1.1423e+00)\tAcc@1 68.750(65.532)\tAcc@5 100.000(94.926)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.092( 0.125)\tLoss 1.4518e+00(1.1652e+00)\tAcc@1 53.333(64.563)\tAcc@5 86.667(94.592)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.563 Acc@5 94.592 Acc@10 99.324\n",
      "==> Epoch 31/50\n",
      "Train batch 10/114\t Loss 0.278130 (0.144516)\n",
      "Train batch 20/114\t Loss 0.300045 (0.169166)\n",
      "Train batch 30/114\t Loss 0.125833 (0.179866)\n",
      "Train batch 40/114\t Loss 0.202691 (0.187443)\n",
      "Train batch 50/114\t Loss 0.150125 (0.178048)\n",
      "Train batch 60/114\t Loss 0.241131 (0.174343)\n",
      "Train batch 70/114\t Loss 0.128773 (0.173966)\n",
      "Train batch 80/114\t Loss 0.129291 (0.174806)\n",
      "Train batch 90/114\t Loss 0.154346 (0.172127)\n",
      "Train batch 100/114\t Loss 0.289478 (0.170557)\n",
      "Train batch 110/114\t Loss 0.103736 (0.168599)\n",
      "Test:[  0/111]\tTime  0.731( 0.731)\tLoss 1.2646e+00(1.2646e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.014( 0.154)\tLoss 5.6400e-01(9.4409e-01)\tAcc@1 81.250(72.159)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.380( 0.146)\tLoss 7.5882e-01(9.5278e-01)\tAcc@1 75.000(68.750)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.015( 0.131)\tLoss 6.3096e-01(1.2868e+00)\tAcc@1 75.000(63.306)\tAcc@5 100.000(95.161)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.354( 0.130)\tLoss 2.6023e+00(1.4032e+00)\tAcc@1 37.500(60.518)\tAcc@5 81.250(93.140)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.018( 0.124)\tLoss 1.4242e+00(1.4319e+00)\tAcc@1 68.750(61.152)\tAcc@5 93.750(92.892)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.376( 0.125)\tLoss 7.0234e-01(1.3949e+00)\tAcc@1 75.000(61.680)\tAcc@5 100.000(93.955)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.014( 0.122)\tLoss 9.9978e-01(1.2993e+00)\tAcc@1 56.250(63.028)\tAcc@5 100.000(94.718)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.290( 0.121)\tLoss 2.4987e+00(1.3076e+00)\tAcc@1 43.750(63.272)\tAcc@5 75.000(93.750)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.019( 0.120)\tLoss 4.0922e-01(1.2730e+00)\tAcc@1 81.250(63.049)\tAcc@5 100.000(94.093)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.305( 0.121)\tLoss 7.0058e-01(1.2045e+00)\tAcc@1 62.500(64.480)\tAcc@5 100.000(94.678)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.014( 0.119)\tLoss 1.5318e+00(1.2326e+00)\tAcc@1 60.000(63.662)\tAcc@5 86.667(94.310)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 63.662 Acc@5 94.310 Acc@10 99.324\n",
      "==> Epoch 32/50\n",
      "Train batch 10/114\t Loss 0.192343 (0.142415)\n",
      "Train batch 20/114\t Loss 0.175078 (0.173980)\n",
      "Train batch 30/114\t Loss 0.136790 (0.173202)\n",
      "Train batch 40/114\t Loss 0.069076 (0.170871)\n",
      "Train batch 50/114\t Loss 0.122149 (0.161691)\n",
      "Train batch 60/114\t Loss 0.174657 (0.164705)\n",
      "Train batch 70/114\t Loss 0.138449 (0.162996)\n",
      "Train batch 80/114\t Loss 0.201827 (0.164388)\n",
      "Train batch 90/114\t Loss 0.083276 (0.167307)\n",
      "Train batch 100/114\t Loss 0.136533 (0.167884)\n",
      "Train batch 110/114\t Loss 0.161567 (0.165835)\n",
      "Test:[  0/111]\tTime  0.649( 0.649)\tLoss 1.1924e+00(1.1924e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.036( 0.147)\tLoss 5.3842e-01(9.1536e-01)\tAcc@1 81.250(74.432)\tAcc@5 100.000(94.886)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.443( 0.142)\tLoss 7.4470e-01(9.4240e-01)\tAcc@1 75.000(71.131)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.051( 0.129)\tLoss 7.3044e-01(1.2655e+00)\tAcc@1 68.750(65.323)\tAcc@5 100.000(94.355)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.388( 0.129)\tLoss 2.5911e+00(1.3922e+00)\tAcc@1 37.500(62.195)\tAcc@5 75.000(92.073)\tAcc@10 93.750(98.171)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 50/111]\tTime  0.017( 0.122)\tLoss 1.5155e+00(1.4417e+00)\tAcc@1 62.500(61.397)\tAcc@5 87.500(91.912)\tAcc@10 100.000(98.407)\n",
      "Test:[ 60/111]\tTime  0.419( 0.124)\tLoss 7.3141e-01(1.3993e+00)\tAcc@1 81.250(61.885)\tAcc@5 100.000(93.033)\tAcc@10 100.000(98.668)\n",
      "Test:[ 70/111]\tTime  0.014( 0.120)\tLoss 9.5455e-01(1.3039e+00)\tAcc@1 62.500(63.468)\tAcc@5 100.000(93.926)\tAcc@10 100.000(98.856)\n",
      "Test:[ 80/111]\tTime  0.398( 0.121)\tLoss 2.6337e+00(1.3187e+00)\tAcc@1 43.750(63.503)\tAcc@5 75.000(93.210)\tAcc@10 93.750(98.920)\n",
      "Test:[ 90/111]\tTime  0.015( 0.119)\tLoss 4.0993e-01(1.2927e+00)\tAcc@1 81.250(63.049)\tAcc@5 100.000(93.544)\tAcc@10 100.000(99.038)\n",
      "Test:[100/111]\tTime  0.412( 0.120)\tLoss 6.4623e-01(1.2208e+00)\tAcc@1 68.750(64.666)\tAcc@5 100.000(94.183)\tAcc@10 100.000(99.134)\n",
      "Test:[110/111]\tTime  0.014( 0.119)\tLoss 1.6303e+00(1.2437e+00)\tAcc@1 46.667(63.944)\tAcc@5 86.667(93.915)\tAcc@10 100.000(99.211)\n",
      " * Acc@1 63.944 Acc@5 93.915 Acc@10 99.211\n",
      "==> Epoch 33/50\n",
      "Train batch 10/114\t Loss 0.143452 (0.172319)\n",
      "Train batch 20/114\t Loss 0.140913 (0.163333)\n",
      "Train batch 30/114\t Loss 0.079953 (0.167970)\n",
      "Train batch 40/114\t Loss 0.158314 (0.164658)\n",
      "Train batch 50/114\t Loss 0.184389 (0.170373)\n",
      "Train batch 60/114\t Loss 0.200909 (0.172305)\n",
      "Train batch 70/114\t Loss 0.236186 (0.174387)\n",
      "Train batch 80/114\t Loss 0.087251 (0.174260)\n",
      "Train batch 90/114\t Loss 0.183698 (0.172334)\n",
      "Train batch 100/114\t Loss 0.259588 (0.173133)\n",
      "Train batch 110/114\t Loss 0.089810 (0.173472)\n",
      "Test:[  0/111]\tTime  0.790( 0.790)\tLoss 1.1903e+00(1.1903e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.019( 0.163)\tLoss 5.3375e-01(8.9344e-01)\tAcc@1 81.250(74.432)\tAcc@5 100.000(96.023)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.343( 0.154)\tLoss 7.6291e-01(9.1832e-01)\tAcc@1 75.000(70.536)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.021( 0.141)\tLoss 6.1890e-01(1.2401e+00)\tAcc@1 75.000(65.121)\tAcc@5 100.000(95.363)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.308( 0.145)\tLoss 2.5907e+00(1.3621e+00)\tAcc@1 37.500(62.195)\tAcc@5 75.000(92.988)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.017( 0.138)\tLoss 1.4050e+00(1.4065e+00)\tAcc@1 62.500(62.377)\tAcc@5 93.750(92.647)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.470( 0.141)\tLoss 7.3244e-01(1.3633e+00)\tAcc@1 81.250(62.807)\tAcc@5 93.750(93.545)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.018( 0.135)\tLoss 9.1940e-01(1.2686e+00)\tAcc@1 62.500(64.613)\tAcc@5 100.000(94.454)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.398( 0.134)\tLoss 2.5067e+00(1.2784e+00)\tAcc@1 43.750(64.815)\tAcc@5 68.750(93.596)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.021( 0.132)\tLoss 4.7679e-01(1.2477e+00)\tAcc@1 81.250(64.492)\tAcc@5 100.000(94.025)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.427( 0.133)\tLoss 5.9397e-01(1.1805e+00)\tAcc@1 75.000(65.842)\tAcc@5 100.000(94.616)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.014( 0.130)\tLoss 1.5399e+00(1.2033e+00)\tAcc@1 53.333(65.183)\tAcc@5 86.667(94.310)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 65.183 Acc@5 94.310 Acc@10 99.324\n",
      "==> Epoch 34/50\n",
      "Train batch 10/114\t Loss 0.051999 (0.190723)\n",
      "Train batch 20/114\t Loss 0.157108 (0.181202)\n",
      "Train batch 30/114\t Loss 0.132389 (0.186107)\n",
      "Train batch 40/114\t Loss 0.065658 (0.172131)\n",
      "Train batch 50/114\t Loss 0.381699 (0.181396)\n",
      "Train batch 60/114\t Loss 0.125732 (0.178766)\n",
      "Train batch 70/114\t Loss 0.150452 (0.173206)\n",
      "Train batch 80/114\t Loss 0.229942 (0.175923)\n",
      "Train batch 90/114\t Loss 0.140639 (0.179094)\n",
      "Train batch 100/114\t Loss 0.182124 (0.177981)\n",
      "Train batch 110/114\t Loss 0.224414 (0.179957)\n",
      "Test:[  0/111]\tTime  0.657( 0.657)\tLoss 1.1824e+00(1.1824e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.027( 0.151)\tLoss 5.5083e-01(9.0004e-01)\tAcc@1 81.250(75.000)\tAcc@5 100.000(96.591)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.366( 0.141)\tLoss 7.5421e-01(9.3974e-01)\tAcc@1 68.750(70.238)\tAcc@5 100.000(97.619)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.017( 0.126)\tLoss 6.1601e-01(1.2558e+00)\tAcc@1 81.250(64.516)\tAcc@5 100.000(95.766)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.369( 0.127)\tLoss 2.5997e+00(1.3741e+00)\tAcc@1 37.500(62.043)\tAcc@5 81.250(93.598)\tAcc@10 93.750(98.476)\n",
      "Test:[ 50/111]\tTime  0.021( 0.121)\tLoss 1.3332e+00(1.4053e+00)\tAcc@1 62.500(62.255)\tAcc@5 93.750(93.137)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.357( 0.122)\tLoss 7.2771e-01(1.3600e+00)\tAcc@1 81.250(62.602)\tAcc@5 93.750(93.955)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.015( 0.118)\tLoss 9.1276e-01(1.2618e+00)\tAcc@1 68.750(64.437)\tAcc@5 100.000(94.806)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.268( 0.119)\tLoss 2.5058e+00(1.2700e+00)\tAcc@1 50.000(64.738)\tAcc@5 75.000(93.904)\tAcc@10 93.750(99.151)\n",
      "Test:[ 90/111]\tTime  0.019( 0.118)\tLoss 4.3991e-01(1.2375e+00)\tAcc@1 81.250(64.835)\tAcc@5 100.000(94.231)\tAcc@10 100.000(99.245)\n",
      "Test:[100/111]\tTime  0.252( 0.118)\tLoss 6.2173e-01(1.1692e+00)\tAcc@1 75.000(66.151)\tAcc@5 100.000(94.802)\tAcc@10 100.000(99.319)\n",
      "Test:[110/111]\tTime  0.014( 0.117)\tLoss 1.5690e+00(1.1954e+00)\tAcc@1 60.000(65.352)\tAcc@5 86.667(94.423)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 65.352 Acc@5 94.423 Acc@10 99.324\n",
      "==> Epoch 35/50\n",
      "Train batch 10/114\t Loss 0.100945 (0.138428)\n",
      "Train batch 20/114\t Loss 0.260639 (0.192727)\n",
      "Train batch 30/114\t Loss 0.149321 (0.189335)\n",
      "Train batch 40/114\t Loss 0.267684 (0.180624)\n",
      "Train batch 50/114\t Loss 0.160676 (0.178418)\n",
      "Train batch 60/114\t Loss 0.135719 (0.174442)\n",
      "Train batch 70/114\t Loss 0.234084 (0.177395)\n",
      "Train batch 80/114\t Loss 0.115296 (0.174111)\n",
      "Train batch 90/114\t Loss 0.115488 (0.173752)\n",
      "Train batch 100/114\t Loss 0.204914 (0.175618)\n",
      "Train batch 110/114\t Loss 0.221624 (0.174995)\n",
      "Test:[  0/111]\tTime  0.649( 0.649)\tLoss 1.3075e+00(1.3075e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.049( 0.148)\tLoss 5.6872e-01(9.5221e-01)\tAcc@1 81.250(73.295)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.384( 0.140)\tLoss 8.1018e-01(9.6901e-01)\tAcc@1 68.750(68.750)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.047( 0.126)\tLoss 6.3743e-01(1.3082e+00)\tAcc@1 81.250(63.508)\tAcc@5 100.000(94.960)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.377( 0.127)\tLoss 2.6529e+00(1.4241e+00)\tAcc@1 37.500(60.976)\tAcc@5 81.250(92.683)\tAcc@10 93.750(98.171)\n",
      "Test:[ 50/111]\tTime  0.019( 0.120)\tLoss 1.4024e+00(1.4471e+00)\tAcc@1 62.500(61.397)\tAcc@5 93.750(92.402)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.366( 0.121)\tLoss 6.9252e-01(1.3981e+00)\tAcc@1 75.000(61.783)\tAcc@5 100.000(93.545)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.019( 0.117)\tLoss 9.1262e-01(1.2988e+00)\tAcc@1 62.500(63.292)\tAcc@5 100.000(94.366)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.359( 0.118)\tLoss 2.4960e+00(1.3108e+00)\tAcc@1 43.750(63.349)\tAcc@5 81.250(93.596)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.017( 0.116)\tLoss 4.5233e-01(1.2771e+00)\tAcc@1 81.250(63.049)\tAcc@5 100.000(93.956)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.378( 0.118)\tLoss 6.6675e-01(1.2085e+00)\tAcc@1 68.750(64.542)\tAcc@5 100.000(94.554)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.013( 0.115)\tLoss 1.5450e+00(1.2345e+00)\tAcc@1 60.000(63.775)\tAcc@5 86.667(94.254)\tAcc@10 100.000(99.268)\n",
      " * Acc@1 63.775 Acc@5 94.254 Acc@10 99.268\n",
      "==> Epoch 36/50\n",
      "Train batch 10/114\t Loss 0.310678 (0.163163)\n",
      "Train batch 20/114\t Loss 0.287393 (0.184972)\n",
      "Train batch 30/114\t Loss 0.258777 (0.173606)\n",
      "Train batch 40/114\t Loss 0.095598 (0.168509)\n",
      "Train batch 50/114\t Loss 0.158003 (0.171673)\n",
      "Train batch 60/114\t Loss 0.139555 (0.173806)\n",
      "Train batch 70/114\t Loss 0.206983 (0.179829)\n",
      "Train batch 80/114\t Loss 0.138175 (0.178312)\n",
      "Train batch 90/114\t Loss 0.166930 (0.180952)\n",
      "Train batch 100/114\t Loss 0.132728 (0.180183)\n",
      "Train batch 110/114\t Loss 0.162571 (0.178177)\n",
      "Test:[  0/111]\tTime  0.665( 0.665)\tLoss 1.2577e+00(1.2577e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.073( 0.152)\tLoss 5.4495e-01(9.3876e-01)\tAcc@1 81.250(71.023)\tAcc@5 100.000(95.455)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.354( 0.141)\tLoss 7.8252e-01(9.5695e-01)\tAcc@1 68.750(68.452)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.052( 0.127)\tLoss 6.0180e-01(1.2752e+00)\tAcc@1 81.250(63.105)\tAcc@5 100.000(94.960)\tAcc@10 100.000(98.790)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 40/111]\tTime  0.372( 0.128)\tLoss 2.6110e+00(1.3923e+00)\tAcc@1 43.750(60.518)\tAcc@5 81.250(92.988)\tAcc@10 93.750(98.171)\n",
      "Test:[ 50/111]\tTime  0.033( 0.121)\tLoss 1.4733e+00(1.4340e+00)\tAcc@1 62.500(61.029)\tAcc@5 87.500(92.525)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.378( 0.123)\tLoss 7.1680e-01(1.3846e+00)\tAcc@1 75.000(61.578)\tAcc@5 100.000(93.545)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.023( 0.118)\tLoss 8.0093e-01(1.2853e+00)\tAcc@1 75.000(63.468)\tAcc@5 100.000(94.366)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.351( 0.119)\tLoss 2.5139e+00(1.2933e+00)\tAcc@1 37.500(63.812)\tAcc@5 68.750(93.519)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.017( 0.117)\tLoss 4.6249e-01(1.2603e+00)\tAcc@1 81.250(63.324)\tAcc@5 100.000(93.887)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.354( 0.119)\tLoss 6.2383e-01(1.1930e+00)\tAcc@1 62.500(64.728)\tAcc@5 100.000(94.431)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 1.4479e+00(1.2144e+00)\tAcc@1 66.667(64.169)\tAcc@5 86.667(94.141)\tAcc@10 100.000(99.268)\n",
      " * Acc@1 64.169 Acc@5 94.141 Acc@10 99.268\n",
      "==> Epoch 37/50\n",
      "Train batch 10/114\t Loss 0.167402 (0.204455)\n",
      "Train batch 20/114\t Loss 0.173999 (0.194800)\n",
      "Train batch 30/114\t Loss 0.147768 (0.180094)\n",
      "Train batch 40/114\t Loss 0.175166 (0.183065)\n",
      "Train batch 50/114\t Loss 0.202781 (0.178659)\n",
      "Train batch 60/114\t Loss 0.138114 (0.178933)\n",
      "Train batch 70/114\t Loss 0.273306 (0.174306)\n",
      "Train batch 80/114\t Loss 0.119852 (0.169685)\n",
      "Train batch 90/114\t Loss 0.061461 (0.167237)\n",
      "Train batch 100/114\t Loss 0.144710 (0.167859)\n",
      "Train batch 110/114\t Loss 0.108917 (0.165969)\n",
      "Test:[  0/111]\tTime  0.646( 0.646)\tLoss 1.1778e+00(1.1778e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.119( 0.153)\tLoss 5.5203e-01(9.0964e-01)\tAcc@1 81.250(74.432)\tAcc@5 100.000(96.023)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.316( 0.139)\tLoss 7.6689e-01(9.4197e-01)\tAcc@1 68.750(69.643)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.105( 0.127)\tLoss 6.8216e-01(1.2448e+00)\tAcc@1 68.750(64.113)\tAcc@5 100.000(95.363)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.309( 0.126)\tLoss 2.4909e+00(1.3685e+00)\tAcc@1 37.500(61.280)\tAcc@5 81.250(93.293)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.079( 0.121)\tLoss 1.3962e+00(1.4111e+00)\tAcc@1 62.500(61.275)\tAcc@5 93.750(92.892)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.318( 0.122)\tLoss 6.9889e-01(1.3626e+00)\tAcc@1 81.250(61.885)\tAcc@5 93.750(93.750)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.062( 0.118)\tLoss 8.7925e-01(1.2643e+00)\tAcc@1 68.750(63.908)\tAcc@5 100.000(94.630)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.315( 0.119)\tLoss 2.4496e+00(1.2743e+00)\tAcc@1 43.750(64.198)\tAcc@5 68.750(93.673)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.059( 0.117)\tLoss 4.7047e-01(1.2465e+00)\tAcc@1 75.000(63.942)\tAcc@5 100.000(94.025)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.314( 0.118)\tLoss 6.1707e-01(1.1788e+00)\tAcc@1 75.000(65.408)\tAcc@5 100.000(94.616)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.014( 0.116)\tLoss 1.4945e+00(1.1990e+00)\tAcc@1 53.333(64.789)\tAcc@5 86.667(94.423)\tAcc@10 100.000(99.268)\n",
      " * Acc@1 64.789 Acc@5 94.423 Acc@10 99.268\n",
      "==> Epoch 38/50\n",
      "Train batch 10/114\t Loss 0.195046 (0.187534)\n",
      "Train batch 20/114\t Loss 0.403836 (0.206719)\n",
      "Train batch 30/114\t Loss 0.141120 (0.192446)\n",
      "Train batch 40/114\t Loss 0.210775 (0.189213)\n",
      "Train batch 50/114\t Loss 0.161929 (0.184649)\n",
      "Train batch 60/114\t Loss 0.190135 (0.180525)\n",
      "Train batch 70/114\t Loss 0.267786 (0.178982)\n",
      "Train batch 80/114\t Loss 0.196868 (0.175471)\n",
      "Train batch 90/114\t Loss 0.084086 (0.178806)\n",
      "Train batch 100/114\t Loss 0.119795 (0.174031)\n",
      "Train batch 110/114\t Loss 0.122075 (0.174002)\n",
      "Test:[  0/111]\tTime  0.652( 0.652)\tLoss 1.2213e+00(1.2213e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.042( 0.148)\tLoss 6.0106e-01(9.3807e-01)\tAcc@1 81.250(74.432)\tAcc@5 100.000(94.886)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.408( 0.141)\tLoss 7.8687e-01(9.6082e-01)\tAcc@1 68.750(70.238)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.030( 0.125)\tLoss 6.8953e-01(1.2810e+00)\tAcc@1 75.000(64.718)\tAcc@5 100.000(94.355)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.389( 0.127)\tLoss 2.5612e+00(1.3975e+00)\tAcc@1 37.500(61.738)\tAcc@5 81.250(92.530)\tAcc@10 93.750(98.476)\n",
      "Test:[ 50/111]\tTime  0.020( 0.120)\tLoss 1.4761e+00(1.4332e+00)\tAcc@1 62.500(61.275)\tAcc@5 93.750(92.402)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.393( 0.122)\tLoss 6.9038e-01(1.3824e+00)\tAcc@1 81.250(61.680)\tAcc@5 100.000(93.443)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.016( 0.118)\tLoss 9.0049e-01(1.2857e+00)\tAcc@1 68.750(63.556)\tAcc@5 100.000(94.366)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.383( 0.119)\tLoss 2.5148e+00(1.2963e+00)\tAcc@1 43.750(63.889)\tAcc@5 75.000(93.519)\tAcc@10 93.750(99.151)\n",
      "Test:[ 90/111]\tTime  0.016( 0.116)\tLoss 4.8249e-01(1.2683e+00)\tAcc@1 81.250(63.530)\tAcc@5 100.000(93.887)\tAcc@10 100.000(99.245)\n",
      "Test:[100/111]\tTime  0.382( 0.118)\tLoss 6.6134e-01(1.2021e+00)\tAcc@1 68.750(64.790)\tAcc@5 100.000(94.493)\tAcc@10 100.000(99.319)\n",
      "Test:[110/111]\tTime  0.014( 0.115)\tLoss 1.5708e+00(1.2269e+00)\tAcc@1 60.000(63.944)\tAcc@5 86.667(94.197)\tAcc@10 100.000(99.380)\n",
      " * Acc@1 63.944 Acc@5 94.197 Acc@10 99.380\n",
      "==> Epoch 39/50\n",
      "Train batch 10/114\t Loss 0.103889 (0.210428)\n",
      "Train batch 20/114\t Loss 0.190359 (0.193897)\n",
      "Train batch 30/114\t Loss 0.128155 (0.193244)\n",
      "Train batch 40/114\t Loss 0.141676 (0.188675)\n",
      "Train batch 50/114\t Loss 0.170362 (0.181029)\n",
      "Train batch 60/114\t Loss 0.121027 (0.184169)\n",
      "Train batch 70/114\t Loss 0.170746 (0.182456)\n",
      "Train batch 80/114\t Loss 0.252984 (0.179444)\n",
      "Train batch 90/114\t Loss 0.102273 (0.175672)\n",
      "Train batch 100/114\t Loss 0.315160 (0.175824)\n",
      "Train batch 110/114\t Loss 0.217004 (0.174780)\n",
      "Test:[  0/111]\tTime  0.647( 0.647)\tLoss 1.2235e+00(1.2235e+00)\tAcc@1 75.000(75.000)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.018( 0.147)\tLoss 5.4935e-01(9.2727e-01)\tAcc@1 81.250(72.727)\tAcc@5 100.000(94.886)\tAcc@10 100.000(98.864)\n",
      "Test:[ 20/111]\tTime  0.410( 0.142)\tLoss 7.7607e-01(9.5090e-01)\tAcc@1 68.750(69.643)\tAcc@5 100.000(96.726)\tAcc@10 100.000(99.405)\n",
      "Test:[ 30/111]\tTime  0.021( 0.126)\tLoss 6.3674e-01(1.2668e+00)\tAcc@1 81.250(64.315)\tAcc@5 100.000(94.556)\tAcc@10 100.000(98.790)\n",
      "Test:[ 40/111]\tTime  0.402( 0.128)\tLoss 2.5609e+00(1.3823e+00)\tAcc@1 37.500(61.433)\tAcc@5 81.250(92.683)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.015( 0.121)\tLoss 1.4902e+00(1.4241e+00)\tAcc@1 62.500(61.765)\tAcc@5 87.500(92.279)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.444( 0.123)\tLoss 6.9326e-01(1.3751e+00)\tAcc@1 75.000(61.988)\tAcc@5 100.000(93.443)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.015( 0.119)\tLoss 8.6421e-01(1.2764e+00)\tAcc@1 68.750(63.908)\tAcc@5 100.000(94.278)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.379( 0.120)\tLoss 2.5368e+00(1.2855e+00)\tAcc@1 37.500(64.198)\tAcc@5 68.750(93.441)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.017( 0.117)\tLoss 4.0650e-01(1.2535e+00)\tAcc@1 81.250(63.805)\tAcc@5 100.000(93.819)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.414( 0.119)\tLoss 6.7580e-01(1.1850e+00)\tAcc@1 62.500(65.037)\tAcc@5 100.000(94.431)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 1.4474e+00(1.2066e+00)\tAcc@1 66.667(64.394)\tAcc@5 86.667(94.141)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.394 Acc@5 94.141 Acc@10 99.324\n",
      "==> Epoch 40/50\n",
      "Train batch 10/114\t Loss 0.150636 (0.170980)\n",
      "Train batch 20/114\t Loss 0.152061 (0.169078)\n",
      "Train batch 30/114\t Loss 0.120828 (0.172527)\n",
      "Train batch 40/114\t Loss 0.286594 (0.175171)\n",
      "Train batch 50/114\t Loss 0.129478 (0.180273)\n",
      "Train batch 60/114\t Loss 0.091145 (0.179451)\n",
      "Train batch 70/114\t Loss 0.231530 (0.175732)\n",
      "Train batch 80/114\t Loss 0.116020 (0.175419)\n",
      "Train batch 90/114\t Loss 0.185477 (0.175909)\n",
      "Train batch 100/114\t Loss 0.126251 (0.175490)\n",
      "Train batch 110/114\t Loss 0.110337 (0.170740)\n",
      "Test:[  0/111]\tTime  0.657( 0.657)\tLoss 1.2111e+00(1.2111e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.027( 0.147)\tLoss 5.3829e-01(9.0883e-01)\tAcc@1 81.250(73.864)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.384( 0.140)\tLoss 7.5920e-01(9.3153e-01)\tAcc@1 68.750(69.940)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 30/111]\tTime  0.016( 0.126)\tLoss 6.5891e-01(1.2500e+00)\tAcc@1 68.750(63.710)\tAcc@5 100.000(94.960)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.415( 0.129)\tLoss 2.6015e+00(1.3744e+00)\tAcc@1 37.500(61.128)\tAcc@5 75.000(92.683)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.057( 0.122)\tLoss 1.4109e+00(1.4132e+00)\tAcc@1 68.750(61.152)\tAcc@5 93.750(92.525)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.357( 0.123)\tLoss 7.1232e-01(1.3629e+00)\tAcc@1 81.250(61.783)\tAcc@5 93.750(93.443)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.045( 0.119)\tLoss 8.4667e-01(1.2662e+00)\tAcc@1 68.750(63.732)\tAcc@5 100.000(94.366)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.329( 0.120)\tLoss 2.4620e+00(1.2773e+00)\tAcc@1 43.750(64.043)\tAcc@5 68.750(93.519)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.032( 0.118)\tLoss 4.6407e-01(1.2457e+00)\tAcc@1 81.250(63.805)\tAcc@5 100.000(93.887)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.315( 0.118)\tLoss 5.6658e-01(1.1785e+00)\tAcc@1 75.000(65.161)\tAcc@5 100.000(94.493)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.014( 0.116)\tLoss 1.5237e+00(1.2017e+00)\tAcc@1 60.000(64.451)\tAcc@5 86.667(94.197)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.451 Acc@5 94.197 Acc@10 99.324\n",
      "==> Epoch 41/50\n",
      "Train batch 10/114\t Loss 0.087478 (0.115810)\n",
      "Train batch 20/114\t Loss 0.068806 (0.128039)\n",
      "Train batch 30/114\t Loss 0.317485 (0.139206)\n",
      "Train batch 40/114\t Loss 0.339491 (0.156556)\n",
      "Train batch 50/114\t Loss 0.418943 (0.164780)\n",
      "Train batch 60/114\t Loss 0.123038 (0.169984)\n",
      "Train batch 70/114\t Loss 0.193028 (0.165792)\n",
      "Train batch 80/114\t Loss 0.201491 (0.166386)\n",
      "Train batch 90/114\t Loss 0.093506 (0.168639)\n",
      "Train batch 100/114\t Loss 0.114809 (0.167392)\n",
      "Train batch 110/114\t Loss 0.176645 (0.165626)\n",
      "Test:[  0/111]\tTime  0.653( 0.653)\tLoss 1.2401e+00(1.2401e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.030( 0.146)\tLoss 5.2732e-01(9.2217e-01)\tAcc@1 81.250(73.295)\tAcc@5 100.000(96.023)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.389( 0.140)\tLoss 7.4953e-01(9.3474e-01)\tAcc@1 68.750(69.048)\tAcc@5 100.000(97.619)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.015( 0.126)\tLoss 6.3510e-01(1.2708e+00)\tAcc@1 75.000(64.113)\tAcc@5 100.000(95.766)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.373( 0.127)\tLoss 2.5622e+00(1.3896e+00)\tAcc@1 37.500(61.280)\tAcc@5 81.250(93.445)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.015( 0.121)\tLoss 1.3436e+00(1.4187e+00)\tAcc@1 68.750(61.397)\tAcc@5 93.750(93.137)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.372( 0.122)\tLoss 6.8497e-01(1.3822e+00)\tAcc@1 81.250(61.988)\tAcc@5 93.750(94.057)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.015( 0.119)\tLoss 9.8736e-01(1.2863e+00)\tAcc@1 68.750(63.820)\tAcc@5 100.000(94.894)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.294( 0.119)\tLoss 2.5068e+00(1.2949e+00)\tAcc@1 43.750(64.120)\tAcc@5 81.250(94.059)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.015( 0.117)\tLoss 4.5366e-01(1.2616e+00)\tAcc@1 81.250(64.148)\tAcc@5 100.000(94.368)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.320( 0.118)\tLoss 6.4221e-01(1.1929e+00)\tAcc@1 68.750(65.470)\tAcc@5 100.000(94.926)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 1.5484e+00(1.2209e+00)\tAcc@1 53.333(64.394)\tAcc@5 86.667(94.592)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.394 Acc@5 94.592 Acc@10 99.324\n",
      "==> Epoch 42/50\n",
      "Train batch 10/114\t Loss 0.147922 (0.189494)\n",
      "Train batch 20/114\t Loss 0.314889 (0.182063)\n",
      "Train batch 30/114\t Loss 0.062207 (0.162179)\n",
      "Train batch 40/114\t Loss 0.091417 (0.152611)\n",
      "Train batch 50/114\t Loss 0.099344 (0.143248)\n",
      "Train batch 60/114\t Loss 0.116191 (0.142461)\n",
      "Train batch 70/114\t Loss 0.134826 (0.144610)\n",
      "Train batch 80/114\t Loss 0.195619 (0.146814)\n",
      "Train batch 90/114\t Loss 0.380943 (0.150442)\n",
      "Train batch 100/114\t Loss 0.205484 (0.151904)\n",
      "Train batch 110/114\t Loss 0.201006 (0.154925)\n",
      "Test:[  0/111]\tTime  0.647( 0.647)\tLoss 1.2805e+00(1.2805e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.035( 0.146)\tLoss 5.4954e-01(9.6476e-01)\tAcc@1 81.250(73.864)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.406( 0.140)\tLoss 7.5756e-01(9.6320e-01)\tAcc@1 75.000(69.345)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.021( 0.125)\tLoss 6.6465e-01(1.2716e+00)\tAcc@1 75.000(63.306)\tAcc@5 100.000(95.363)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.383( 0.127)\tLoss 2.5155e+00(1.3950e+00)\tAcc@1 43.750(60.823)\tAcc@5 75.000(93.140)\tAcc@10 93.750(98.476)\n",
      "Test:[ 50/111]\tTime  0.021( 0.120)\tLoss 1.3987e+00(1.4288e+00)\tAcc@1 68.750(60.907)\tAcc@5 93.750(93.015)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.399( 0.122)\tLoss 7.1220e-01(1.3783e+00)\tAcc@1 81.250(61.578)\tAcc@5 93.750(93.852)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.032( 0.118)\tLoss 8.0855e-01(1.2819e+00)\tAcc@1 68.750(63.380)\tAcc@5 100.000(94.718)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.331( 0.119)\tLoss 2.3866e+00(1.2887e+00)\tAcc@1 43.750(63.966)\tAcc@5 81.250(93.981)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.020( 0.118)\tLoss 5.3534e-01(1.2623e+00)\tAcc@1 75.000(63.393)\tAcc@5 100.000(94.299)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.283( 0.118)\tLoss 6.3895e-01(1.1990e+00)\tAcc@1 68.750(64.728)\tAcc@5 100.000(94.864)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.013( 0.118)\tLoss 1.4343e+00(1.2186e+00)\tAcc@1 66.667(64.282)\tAcc@5 86.667(94.704)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.282 Acc@5 94.704 Acc@10 99.324\n",
      "==> Epoch 43/50\n",
      "Train batch 10/114\t Loss 0.244291 (0.188904)\n",
      "Train batch 20/114\t Loss 0.173804 (0.178279)\n",
      "Train batch 30/114\t Loss 0.297012 (0.170244)\n",
      "Train batch 40/114\t Loss 0.162977 (0.172336)\n",
      "Train batch 50/114\t Loss 0.137092 (0.168799)\n",
      "Train batch 60/114\t Loss 0.132568 (0.168359)\n",
      "Train batch 70/114\t Loss 0.230387 (0.166501)\n",
      "Train batch 80/114\t Loss 0.117409 (0.166028)\n",
      "Train batch 90/114\t Loss 0.183052 (0.167634)\n",
      "Train batch 100/114\t Loss 0.106651 (0.167663)\n",
      "Train batch 110/114\t Loss 0.173983 (0.166222)\n",
      "Test:[  0/111]\tTime  0.655( 0.655)\tLoss 1.1772e+00(1.1772e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.026( 0.146)\tLoss 5.0929e-01(9.0010e-01)\tAcc@1 81.250(73.864)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.404( 0.141)\tLoss 7.2756e-01(9.3727e-01)\tAcc@1 68.750(69.345)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.025( 0.125)\tLoss 6.2864e-01(1.2539e+00)\tAcc@1 75.000(64.113)\tAcc@5 100.000(95.161)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.399( 0.127)\tLoss 2.6135e+00(1.3767e+00)\tAcc@1 37.500(61.433)\tAcc@5 75.000(93.140)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.017( 0.120)\tLoss 1.3634e+00(1.4105e+00)\tAcc@1 68.750(61.275)\tAcc@5 93.750(92.892)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.415( 0.122)\tLoss 7.3278e-01(1.3635e+00)\tAcc@1 81.250(61.885)\tAcc@5 93.750(93.750)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.014( 0.118)\tLoss 8.8749e-01(1.2651e+00)\tAcc@1 68.750(63.820)\tAcc@5 100.000(94.630)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.386( 0.119)\tLoss 2.4743e+00(1.2734e+00)\tAcc@1 43.750(64.198)\tAcc@5 81.250(93.827)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.016( 0.116)\tLoss 4.7448e-01(1.2446e+00)\tAcc@1 81.250(64.148)\tAcc@5 100.000(94.231)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.393( 0.118)\tLoss 5.8997e-01(1.1760e+00)\tAcc@1 75.000(65.594)\tAcc@5 100.000(94.802)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.013( 0.115)\tLoss 1.5260e+00(1.1996e+00)\tAcc@1 66.667(64.789)\tAcc@5 86.667(94.535)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.789 Acc@5 94.535 Acc@10 99.324\n",
      "==> Epoch 44/50\n",
      "Train batch 10/114\t Loss 0.070419 (0.141869)\n",
      "Train batch 20/114\t Loss 0.239353 (0.156472)\n",
      "Train batch 30/114\t Loss 0.146769 (0.164617)\n",
      "Train batch 40/114\t Loss 0.187668 (0.164182)\n",
      "Train batch 50/114\t Loss 0.182025 (0.161171)\n",
      "Train batch 60/114\t Loss 0.163386 (0.154759)\n",
      "Train batch 70/114\t Loss 0.150970 (0.155536)\n",
      "Train batch 80/114\t Loss 0.236293 (0.154437)\n",
      "Train batch 90/114\t Loss 0.238732 (0.156184)\n",
      "Train batch 100/114\t Loss 0.142473 (0.159321)\n",
      "Train batch 110/114\t Loss 0.127542 (0.159528)\n",
      "Test:[  0/111]\tTime  0.635( 0.635)\tLoss 1.2363e+00(1.2363e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.022( 0.144)\tLoss 5.1680e-01(9.0897e-01)\tAcc@1 81.250(74.432)\tAcc@5 100.000(96.023)\tAcc@10 100.000(99.432)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 20/111]\tTime  0.410( 0.140)\tLoss 7.2721e-01(9.2450e-01)\tAcc@1 75.000(70.238)\tAcc@5 100.000(97.619)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.017( 0.125)\tLoss 6.3070e-01(1.2562e+00)\tAcc@1 75.000(64.718)\tAcc@5 100.000(95.565)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.404( 0.127)\tLoss 2.5890e+00(1.3762e+00)\tAcc@1 37.500(61.738)\tAcc@5 81.250(93.598)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.025( 0.120)\tLoss 1.4298e+00(1.4123e+00)\tAcc@1 62.500(61.887)\tAcc@5 93.750(93.382)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.394( 0.122)\tLoss 7.0387e-01(1.3684e+00)\tAcc@1 75.000(62.295)\tAcc@5 93.750(94.160)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.016( 0.118)\tLoss 9.1547e-01(1.2735e+00)\tAcc@1 62.500(63.820)\tAcc@5 100.000(94.982)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.367( 0.119)\tLoss 2.4996e+00(1.2836e+00)\tAcc@1 50.000(63.966)\tAcc@5 75.000(93.981)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.020( 0.116)\tLoss 4.0484e-01(1.2501e+00)\tAcc@1 81.250(63.668)\tAcc@5 100.000(94.368)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.388( 0.118)\tLoss 6.3918e-01(1.1817e+00)\tAcc@1 68.750(65.099)\tAcc@5 100.000(94.926)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.019( 0.116)\tLoss 1.4840e+00(1.2060e+00)\tAcc@1 66.667(64.451)\tAcc@5 86.667(94.592)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.451 Acc@5 94.592 Acc@10 99.324\n",
      "==> Epoch 45/50\n",
      "Train batch 10/114\t Loss 0.157086 (0.174797)\n",
      "Train batch 20/114\t Loss 0.229104 (0.171374)\n",
      "Train batch 30/114\t Loss 0.223413 (0.174690)\n",
      "Train batch 40/114\t Loss 0.175228 (0.175746)\n",
      "Train batch 50/114\t Loss 0.191618 (0.164784)\n",
      "Train batch 60/114\t Loss 0.157294 (0.170106)\n",
      "Train batch 70/114\t Loss 0.056722 (0.171147)\n",
      "Train batch 80/114\t Loss 0.121745 (0.176985)\n",
      "Train batch 90/114\t Loss 0.177722 (0.175803)\n",
      "Train batch 100/114\t Loss 0.197751 (0.174648)\n",
      "Train batch 110/114\t Loss 0.240397 (0.174169)\n",
      "Test:[  0/111]\tTime  0.677( 0.677)\tLoss 1.2649e+00(1.2649e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.021( 0.148)\tLoss 5.4621e-01(9.3491e-01)\tAcc@1 81.250(72.159)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.410( 0.142)\tLoss 7.6319e-01(9.4189e-01)\tAcc@1 68.750(68.750)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.016( 0.126)\tLoss 6.1957e-01(1.2634e+00)\tAcc@1 75.000(63.508)\tAcc@5 100.000(95.766)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.407( 0.127)\tLoss 2.6164e+00(1.3803e+00)\tAcc@1 37.500(60.823)\tAcc@5 81.250(93.445)\tAcc@10 93.750(98.476)\n",
      "Test:[ 50/111]\tTime  0.014( 0.120)\tLoss 1.3770e+00(1.4021e+00)\tAcc@1 68.750(61.520)\tAcc@5 93.750(93.137)\tAcc@10 100.000(98.775)\n",
      "Test:[ 60/111]\tTime  0.417( 0.122)\tLoss 6.9057e-01(1.3549e+00)\tAcc@1 81.250(61.988)\tAcc@5 100.000(94.057)\tAcc@10 100.000(98.975)\n",
      "Test:[ 70/111]\tTime  0.014( 0.118)\tLoss 9.0981e-01(1.2597e+00)\tAcc@1 68.750(63.908)\tAcc@5 100.000(94.894)\tAcc@10 100.000(99.120)\n",
      "Test:[ 80/111]\tTime  0.396( 0.119)\tLoss 2.5257e+00(1.2706e+00)\tAcc@1 43.750(64.275)\tAcc@5 81.250(94.136)\tAcc@10 93.750(99.151)\n",
      "Test:[ 90/111]\tTime  0.016( 0.116)\tLoss 4.6243e-01(1.2401e+00)\tAcc@1 81.250(64.080)\tAcc@5 100.000(94.437)\tAcc@10 100.000(99.245)\n",
      "Test:[100/111]\tTime  0.411( 0.118)\tLoss 6.3247e-01(1.1748e+00)\tAcc@1 68.750(65.408)\tAcc@5 100.000(94.988)\tAcc@10 100.000(99.319)\n",
      "Test:[110/111]\tTime  0.012( 0.116)\tLoss 1.5171e+00(1.2030e+00)\tAcc@1 60.000(64.507)\tAcc@5 86.667(94.648)\tAcc@10 100.000(99.380)\n",
      " * Acc@1 64.507 Acc@5 94.648 Acc@10 99.380\n",
      "==> Epoch 46/50\n",
      "Train batch 10/114\t Loss 0.105627 (0.156403)\n",
      "Train batch 20/114\t Loss 0.136129 (0.170553)\n",
      "Train batch 30/114\t Loss 0.343946 (0.185043)\n",
      "Train batch 40/114\t Loss 0.089919 (0.175506)\n",
      "Train batch 50/114\t Loss 0.152157 (0.170493)\n",
      "Train batch 60/114\t Loss 0.298033 (0.172484)\n",
      "Train batch 70/114\t Loss 0.195002 (0.174502)\n",
      "Train batch 80/114\t Loss 0.149475 (0.174625)\n",
      "Train batch 90/114\t Loss 0.135127 (0.170742)\n",
      "Train batch 100/114\t Loss 0.168456 (0.169146)\n",
      "Train batch 110/114\t Loss 0.407954 (0.170837)\n",
      "Test:[  0/111]\tTime  0.662( 0.662)\tLoss 1.2902e+00(1.2902e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.016( 0.149)\tLoss 5.4410e-01(9.2792e-01)\tAcc@1 81.250(73.295)\tAcc@5 100.000(96.023)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.421( 0.143)\tLoss 7.6847e-01(9.4668e-01)\tAcc@1 75.000(69.643)\tAcc@5 100.000(97.619)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.015( 0.127)\tLoss 6.3681e-01(1.2924e+00)\tAcc@1 75.000(63.911)\tAcc@5 100.000(94.960)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.404( 0.128)\tLoss 2.5976e+00(1.4067e+00)\tAcc@1 37.500(61.280)\tAcc@5 81.250(92.683)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.014( 0.121)\tLoss 1.4314e+00(1.4339e+00)\tAcc@1 62.500(61.520)\tAcc@5 93.750(92.525)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.420( 0.123)\tLoss 6.6956e-01(1.3863e+00)\tAcc@1 75.000(61.885)\tAcc@5 100.000(93.545)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.014( 0.119)\tLoss 9.0881e-01(1.2878e+00)\tAcc@1 62.500(63.468)\tAcc@5 100.000(94.366)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.395( 0.120)\tLoss 2.5221e+00(1.3002e+00)\tAcc@1 50.000(63.657)\tAcc@5 75.000(93.441)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.014( 0.117)\tLoss 4.2713e-01(1.2661e+00)\tAcc@1 81.250(63.118)\tAcc@5 100.000(93.819)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.406( 0.118)\tLoss 6.4509e-01(1.1966e+00)\tAcc@1 68.750(64.728)\tAcc@5 100.000(94.431)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 1.5302e+00(1.2228e+00)\tAcc@1 53.333(63.944)\tAcc@5 86.667(94.141)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 63.944 Acc@5 94.141 Acc@10 99.324\n",
      "==> Epoch 47/50\n",
      "Train batch 10/114\t Loss 0.097892 (0.174817)\n",
      "Train batch 20/114\t Loss 0.130502 (0.206153)\n",
      "Train batch 30/114\t Loss 0.072526 (0.199988)\n",
      "Train batch 40/114\t Loss 0.115803 (0.191646)\n",
      "Train batch 50/114\t Loss 0.151946 (0.183757)\n",
      "Train batch 60/114\t Loss 0.251371 (0.182069)\n",
      "Train batch 70/114\t Loss 0.242434 (0.176760)\n",
      "Train batch 80/114\t Loss 0.136179 (0.177592)\n",
      "Train batch 90/114\t Loss 0.286715 (0.184903)\n",
      "Train batch 100/114\t Loss 0.122417 (0.179993)\n",
      "Train batch 110/114\t Loss 0.087755 (0.180113)\n",
      "Test:[  0/111]\tTime  0.649( 0.649)\tLoss 1.1606e+00(1.1606e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.029( 0.147)\tLoss 5.1547e-01(8.9990e-01)\tAcc@1 81.250(73.864)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.411( 0.140)\tLoss 7.4738e-01(9.1389e-01)\tAcc@1 75.000(70.238)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.047( 0.126)\tLoss 6.4077e-01(1.2451e+00)\tAcc@1 75.000(64.919)\tAcc@5 100.000(95.161)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.387( 0.127)\tLoss 2.5815e+00(1.3679e+00)\tAcc@1 37.500(62.043)\tAcc@5 81.250(92.988)\tAcc@10 93.750(98.018)\n",
      "Test:[ 50/111]\tTime  0.018( 0.120)\tLoss 1.3284e+00(1.4053e+00)\tAcc@1 68.750(62.010)\tAcc@5 93.750(92.770)\tAcc@10 100.000(98.407)\n",
      "Test:[ 60/111]\tTime  0.415( 0.122)\tLoss 7.2521e-01(1.3718e+00)\tAcc@1 81.250(62.500)\tAcc@5 100.000(93.852)\tAcc@10 100.000(98.668)\n",
      "Test:[ 70/111]\tTime  0.016( 0.118)\tLoss 9.9939e-01(1.2751e+00)\tAcc@1 68.750(64.261)\tAcc@5 100.000(94.718)\tAcc@10 100.000(98.856)\n",
      "Test:[ 80/111]\tTime  0.394( 0.119)\tLoss 2.4461e+00(1.2852e+00)\tAcc@1 50.000(64.583)\tAcc@5 75.000(93.827)\tAcc@10 93.750(98.920)\n",
      "Test:[ 90/111]\tTime  0.017( 0.116)\tLoss 4.8411e-01(1.2593e+00)\tAcc@1 81.250(64.423)\tAcc@5 100.000(94.162)\tAcc@10 100.000(99.038)\n",
      "Test:[100/111]\tTime  0.399( 0.118)\tLoss 6.3169e-01(1.1905e+00)\tAcc@1 68.750(65.780)\tAcc@5 100.000(94.740)\tAcc@10 100.000(99.134)\n",
      "Test:[110/111]\tTime  0.013( 0.115)\tLoss 1.6250e+00(1.2184e+00)\tAcc@1 53.333(64.676)\tAcc@5 86.667(94.423)\tAcc@10 100.000(99.211)\n",
      " * Acc@1 64.676 Acc@5 94.423 Acc@10 99.211\n",
      "==> Epoch 48/50\n",
      "Train batch 10/114\t Loss 0.177076 (0.159415)\n",
      "Train batch 20/114\t Loss 0.234410 (0.158716)\n",
      "Train batch 30/114\t Loss 0.173226 (0.171016)\n",
      "Train batch 40/114\t Loss 0.148455 (0.160790)\n",
      "Train batch 50/114\t Loss 0.217671 (0.171912)\n",
      "Train batch 60/114\t Loss 0.129890 (0.169114)\n",
      "Train batch 70/114\t Loss 0.117830 (0.167908)\n",
      "Train batch 80/114\t Loss 0.284751 (0.166031)\n",
      "Train batch 90/114\t Loss 0.133781 (0.167104)\n",
      "Train batch 100/114\t Loss 0.162953 (0.165305)\n",
      "Train batch 110/114\t Loss 0.175642 (0.162296)\n",
      "Test:[  0/111]\tTime  0.666( 0.666)\tLoss 1.2169e+00(1.2169e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:[ 10/111]\tTime  0.016( 0.149)\tLoss 5.0525e-01(9.2437e-01)\tAcc@1 81.250(73.295)\tAcc@5 100.000(94.886)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.415( 0.144)\tLoss 7.6731e-01(9.2567e-01)\tAcc@1 75.000(69.940)\tAcc@5 100.000(97.024)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.017( 0.127)\tLoss 6.5614e-01(1.2449e+00)\tAcc@1 75.000(63.911)\tAcc@5 100.000(95.363)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.396( 0.129)\tLoss 2.4944e+00(1.3681e+00)\tAcc@1 37.500(61.280)\tAcc@5 81.250(92.835)\tAcc@10 93.750(98.476)\n",
      "Test:[ 50/111]\tTime  0.014( 0.122)\tLoss 1.3808e+00(1.4078e+00)\tAcc@1 62.500(61.152)\tAcc@5 93.750(92.647)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.416( 0.123)\tLoss 7.2026e-01(1.3574e+00)\tAcc@1 75.000(61.783)\tAcc@5 100.000(93.750)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.014( 0.119)\tLoss 8.4064e-01(1.2611e+00)\tAcc@1 62.500(63.468)\tAcc@5 100.000(94.630)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.389( 0.120)\tLoss 2.3747e+00(1.2715e+00)\tAcc@1 43.750(63.966)\tAcc@5 81.250(93.904)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.015( 0.117)\tLoss 4.6011e-01(1.2459e+00)\tAcc@1 81.250(63.599)\tAcc@5 100.000(94.231)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.405( 0.119)\tLoss 6.4430e-01(1.1795e+00)\tAcc@1 68.750(64.975)\tAcc@5 100.000(94.802)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.012( 0.116)\tLoss 1.4389e+00(1.1997e+00)\tAcc@1 66.667(64.563)\tAcc@5 86.667(94.535)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.563 Acc@5 94.535 Acc@10 99.324\n",
      "==> Epoch 49/50\n",
      "Train batch 10/114\t Loss 0.237956 (0.176283)\n",
      "Train batch 20/114\t Loss 0.144039 (0.188615)\n",
      "Train batch 30/114\t Loss 0.219018 (0.175132)\n",
      "Train batch 40/114\t Loss 0.184074 (0.173749)\n",
      "Train batch 50/114\t Loss 0.040703 (0.169508)\n",
      "Train batch 60/114\t Loss 0.247226 (0.169200)\n",
      "Train batch 70/114\t Loss 0.092938 (0.170491)\n",
      "Train batch 80/114\t Loss 0.209552 (0.169885)\n",
      "Train batch 90/114\t Loss 0.139408 (0.172346)\n",
      "Train batch 100/114\t Loss 0.192525 (0.173454)\n",
      "Train batch 110/114\t Loss 0.104516 (0.174161)\n",
      "Test:[  0/111]\tTime  0.670( 0.670)\tLoss 1.2036e+00(1.2036e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.039( 0.149)\tLoss 5.2030e-01(9.1141e-01)\tAcc@1 81.250(72.727)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.401( 0.141)\tLoss 7.4015e-01(9.2247e-01)\tAcc@1 62.500(68.750)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.020( 0.126)\tLoss 6.1239e-01(1.2391e+00)\tAcc@1 75.000(63.508)\tAcc@5 100.000(95.565)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.407( 0.128)\tLoss 2.5316e+00(1.3597e+00)\tAcc@1 37.500(60.823)\tAcc@5 81.250(93.293)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.019( 0.121)\tLoss 1.4367e+00(1.3963e+00)\tAcc@1 62.500(61.029)\tAcc@5 93.750(93.137)\tAcc@10 100.000(98.652)\n",
      "Test:[ 60/111]\tTime  0.441( 0.123)\tLoss 6.8332e-01(1.3473e+00)\tAcc@1 81.250(61.783)\tAcc@5 100.000(94.160)\tAcc@10 100.000(98.873)\n",
      "Test:[ 70/111]\tTime  0.014( 0.119)\tLoss 8.9380e-01(1.2520e+00)\tAcc@1 68.750(63.732)\tAcc@5 100.000(94.982)\tAcc@10 100.000(99.032)\n",
      "Test:[ 80/111]\tTime  0.388( 0.120)\tLoss 2.4347e+00(1.2612e+00)\tAcc@1 43.750(64.120)\tAcc@5 81.250(94.213)\tAcc@10 93.750(99.074)\n",
      "Test:[ 90/111]\tTime  0.029( 0.117)\tLoss 4.9411e-01(1.2341e+00)\tAcc@1 81.250(64.011)\tAcc@5 100.000(94.505)\tAcc@10 100.000(99.176)\n",
      "Test:[100/111]\tTime  0.597( 0.121)\tLoss 6.1097e-01(1.1681e+00)\tAcc@1 68.750(65.347)\tAcc@5 100.000(95.050)\tAcc@10 100.000(99.257)\n",
      "Test:[110/111]\tTime  0.012( 0.118)\tLoss 1.4412e+00(1.1930e+00)\tAcc@1 66.667(64.507)\tAcc@5 86.667(94.704)\tAcc@10 100.000(99.324)\n",
      " * Acc@1 64.507 Acc@5 94.704 Acc@10 99.324\n",
      "==> Epoch 50/50\n",
      "Train batch 10/114\t Loss 0.097727 (0.141519)\n",
      "Train batch 20/114\t Loss 0.164893 (0.149571)\n",
      "Train batch 30/114\t Loss 0.298903 (0.168503)\n",
      "Train batch 40/114\t Loss 0.191578 (0.170719)\n",
      "Train batch 50/114\t Loss 0.075011 (0.164537)\n",
      "Train batch 60/114\t Loss 0.126960 (0.173887)\n",
      "Train batch 70/114\t Loss 0.203295 (0.173168)\n",
      "Train batch 80/114\t Loss 0.244340 (0.169915)\n",
      "Train batch 90/114\t Loss 0.243190 (0.170560)\n",
      "Train batch 100/114\t Loss 0.127750 (0.164105)\n",
      "Train batch 110/114\t Loss 0.127079 (0.162505)\n",
      "Test:[  0/111]\tTime  0.754( 0.754)\tLoss 1.2033e+00(1.2033e+00)\tAcc@1 81.250(81.250)\tAcc@5 93.750(93.750)\tAcc@10 93.750(93.750)\n",
      "Test:[ 10/111]\tTime  0.030( 0.155)\tLoss 5.2459e-01(8.9912e-01)\tAcc@1 81.250(73.864)\tAcc@5 100.000(95.455)\tAcc@10 100.000(99.432)\n",
      "Test:[ 20/111]\tTime  0.401( 0.145)\tLoss 7.4310e-01(9.1738e-01)\tAcc@1 68.750(69.940)\tAcc@5 100.000(97.321)\tAcc@10 100.000(99.702)\n",
      "Test:[ 30/111]\tTime  0.028( 0.128)\tLoss 6.6588e-01(1.2538e+00)\tAcc@1 68.750(63.710)\tAcc@5 100.000(94.960)\tAcc@10 100.000(98.992)\n",
      "Test:[ 40/111]\tTime  0.409( 0.129)\tLoss 2.6065e+00(1.3835e+00)\tAcc@1 37.500(61.128)\tAcc@5 75.000(92.683)\tAcc@10 93.750(98.323)\n",
      "Test:[ 50/111]\tTime  0.014( 0.122)\tLoss 1.3769e+00(1.4222e+00)\tAcc@1 62.500(61.029)\tAcc@5 93.750(92.402)\tAcc@10 100.000(98.529)\n",
      "Test:[ 60/111]\tTime  0.418( 0.123)\tLoss 6.9910e-01(1.3688e+00)\tAcc@1 81.250(61.680)\tAcc@5 93.750(93.443)\tAcc@10 100.000(98.770)\n",
      "Test:[ 70/111]\tTime  0.014( 0.119)\tLoss 8.4767e-01(1.2689e+00)\tAcc@1 75.000(63.732)\tAcc@5 100.000(94.366)\tAcc@10 100.000(98.944)\n",
      "Test:[ 80/111]\tTime  0.389( 0.120)\tLoss 2.4895e+00(1.2828e+00)\tAcc@1 43.750(63.889)\tAcc@5 75.000(93.519)\tAcc@10 93.750(98.997)\n",
      "Test:[ 90/111]\tTime  0.028( 0.117)\tLoss 4.2491e-01(1.2530e+00)\tAcc@1 81.250(63.668)\tAcc@5 100.000(93.887)\tAcc@10 100.000(99.107)\n",
      "Test:[100/111]\tTime  0.406( 0.119)\tLoss 5.7035e-01(1.1831e+00)\tAcc@1 75.000(65.099)\tAcc@5 100.000(94.493)\tAcc@10 100.000(99.196)\n",
      "Test:[110/111]\tTime  0.013( 0.116)\tLoss 1.5711e+00(1.2076e+00)\tAcc@1 53.333(64.338)\tAcc@5 86.667(94.197)\tAcc@10 100.000(99.268)\n",
      " * Acc@1 64.338 Acc@5 94.197 Acc@10 99.268\n",
      "The best acc:  tensor(65.3521, device='cuda:0')\n",
      "Finished. Total elapsed time (h:m:s): 0:38:49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>â–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_loss</td><td>â–†â–…â–†â–ˆâ–„â–ƒâ–„â–†â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_top1</td><td>â–â–ƒâ–ƒâ–„â–…â–†â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val_top10</td><td>â–‡â–†â–â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val_top5</td><td>â–„â–ƒâ–â–ƒâ–…â–†â–…â–…â–†â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>The best acc: </td><td>65.35212</td></tr><tr><td>train_loss</td><td>0.16385</td></tr><tr><td>val_loss</td><td>1.20756</td></tr><tr><td>val_top1</td><td>64.33803</td></tr><tr><td>val_top10</td><td>99.26761</td></tr><tr><td>val_top5</td><td>94.19719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misunderstood-aardvark-14</strong>: <a href=\"https://wandb.ai/nhquanst/Afosr_2022_MHI/runs/2kkk3gzw\" target=\"_blank\">https://wandb.ai/nhquanst/Afosr_2022_MHI/runs/2kkk3gzw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220607_211748-2kkk3gzw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ðŸ initialise a wandb run\n",
    "wandb.init(\n",
    "    project=\"Afosr_2022_MHI\",\n",
    "    config={\n",
    "        \"project\":\"Afosr_2022_MHI\",\n",
    "        \"data_path\":\"/mnt/works/projectComvis/AFOSR-2020/MotionHistoryImage/MHI_images\",\n",
    "        \"arch\":\"resnet18\",\n",
    "        \"split\":\"split_by_env\",     # split_by_env , split_by_sub  \n",
    "        \"train_batch\":32,\n",
    "        \"test_batch\":16,\n",
    "        \"num_classes\":12,\n",
    "        \"workers\":4,\n",
    "        \"weight_decay\":5e-04,\n",
    "        \"momentum\":0.9,\n",
    "        \"lr\":0.003,\n",
    "        \"gamma\":0.1,\n",
    "        \"max_epoch\":50,\n",
    "        \"stepsize\":10, # to modify lr\n",
    "        \"eval_step\":1, #         \n",
    "        \"print_freq\":10,\n",
    "        })\n",
    "\n",
    "# Copy your config \n",
    "config = wandb.config\n",
    "save_dir = os.path.join(\"./log\", config.project,\"%s_%s\" % (config.arch,config.split))\n",
    "train_list=os.path.join(\"/home/nhquan/datasets/afosr2022\",config.split, \"train.txt\")\n",
    "test_list=os.path.join(\"/home/nhquan/datasets/afosr2022\", config.split,\"val.txt\")\n",
    "\n",
    "\n",
    "# torch.manual_seed(100)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "scaler = transforms.Resize((224,224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])    \n",
    "\n",
    "\n",
    "transform4train= transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=(-90, 90)),\n",
    "    scaler,\n",
    "    transforms.ToTensor(),\n",
    "    normalize       \n",
    "    ])   \n",
    "\n",
    "transform4test= transforms.Compose([\n",
    "    scaler,\n",
    "    transforms.ToTensor(),\n",
    "    normalize       \n",
    "    ])     \n",
    "\n",
    "\n",
    "# trainDataset = datasets.ImageFolder(\"./data/data_huy/train/\",transform)\n",
    "# testDataset=datasets.ImageFolder(\"./data/data_huy/test/\", transform)\n",
    "\n",
    "trainDataset = AfosrDataset(config.data_path,train_list,transform=transform4train) \n",
    "print(\"train item:\",trainDataset.__len__())\n",
    "testDataset = AfosrDataset(config.data_path,test_list,transform=transform4test) \n",
    "print(\"Test item:\",testDataset.__len__())\n",
    "\n",
    "trainLoader = DataLoader(trainDataset, batch_size=config.train_batch, \n",
    "                         shuffle=True, num_workers=config.workers)\n",
    "testLoader = DataLoader(testDataset, batch_size=config.test_batch, \n",
    "                        shuffle=False, num_workers=config.workers)\n",
    "\n",
    "\n",
    "print(\"Initializing model: {}\".format(config.arch))\n",
    "model = models.init_model(name=config.arch, num_classes=config.num_classes)\n",
    "print(\"Model size: {:.5f}M\".format(sum(p.numel() for p in model.parameters())/1000000.0))\n",
    "model.cuda(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion_xent = criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.lr, \n",
    "                            momentum=config.momentum, weight_decay=config.weight_decay)\n",
    "\n",
    "if config.stepsize > 0:\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=config.stepsize, gamma=config.gamma)\n",
    "\n",
    "## Train model\n",
    "train_loss_values=[]\n",
    "test_loss_values=[]\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(111) # for acce\n",
    "fig.show()    \n",
    "# ax.set_xlim(left=0, right=len(lines)+10)\n",
    "        \n",
    "start_time = time.time()\n",
    "best_rank1 = -np.inf\n",
    "for epoch in range(0, config.max_epoch):\n",
    "    print(\"==> Epoch {}/{}\".format(epoch+1, config.max_epoch))        \n",
    "    train_loss=train(model, criterion_xent, optimizer, trainLoader, device).cpu()  \n",
    "    train_loss_values.append(train_loss)\n",
    "    if config.stepsize > 0: scheduler.step()\n",
    "    if (epoch+1)%config.eval_step==0:\n",
    "        val_loss,acc1,acc5,acc10= validate(model, criterion_xent,testLoader,device)\n",
    "        val_loss=val_loss.cpu()\n",
    "        test_loss_values.append(val_loss)\n",
    "        if best_rank1<acc1:\n",
    "            best_rank1=acc1\n",
    "            save_checkpoint({\n",
    "                'state_dict': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                }, False, osp.join(save_dir, 'best_checkpoint'  + '.pth.tar'))\n",
    "        ax.clear()\n",
    "        ax.plot(train_loss_values)\n",
    "        ax.plot(test_loss_values)    \n",
    "        fig.canvas.draw()  \n",
    "        val_log={\"train_loss\": train_loss, \n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_top1\":acc1,\n",
    "               \"val_top5\":acc5,\n",
    "               \"val_top10\":acc10}\n",
    "    wandb.log(val_log)\n",
    "print('The best acc: ',best_rank1)\n",
    "elapsed = round(time.time() - start_time)\n",
    "elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "print(\"Finished. Total elapsed time (h:m:s): {}\".format(elapsed))\n",
    "# plt.plot(train_loss_values)\n",
    "# plt.plot(test_loss_values)\n",
    "\n",
    "wandb.summary['The best acc: '] = best_rank1\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d6240",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de52ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: resnet18\n",
      "Model size: 11.18267M\n",
      "resnet18_split_by_sub: Acc@1 66.253 Acc@5 94.526 Acc@10 99.549\n",
      "Initializing model: resnet18\n",
      "Model size: 11.18267M\n",
      "resnet18_split_by_env: Acc@1 65.352 Acc@5 94.423 Acc@10 99.324\n",
      "Initializing model: resnet50\n",
      "Model size: 23.53262M\n",
      "resnet50_split_by_sub: Acc@1 65.463 Acc@5 94.413 Acc@10 99.436\n",
      "Initializing model: resnet50\n",
      "Model size: 23.53262M\n",
      "resnet50_split_by_env: Acc@1 68.563 Acc@5 97.239 Acc@10 99.887\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import os.path as osp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import models\n",
    "sys.path.append(\"libs\")  # Adds higher directory to python modules path.\n",
    "from utils import accuracy, AverageMeter,ProgressMeter, Logger, FusionMatrix \n",
    "from dataManager import AfosrDataset\n",
    "# from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "for arch in ['resnet18', 'resnet50']:  \n",
    "    for split  in ['split_by_sub', 'split_by_env']: \n",
    "        data_path='/mnt/works/projectComvis/AFOSR-2020/MotionHistoryImage/MHI_images'\n",
    "        test_list = '/home/nhquan/datasets/afosr2022/%s/val.txt' % (split)\n",
    "        save_dir='./log/Afosr_2022_MHI/%s_%s' % (arch,split)\n",
    "        weightFile='./log/Afosr_2022_MHI/%s_%s/best_checkpoint.pth.tar' % (arch,split)\n",
    "        test_batch=32\n",
    "        num_classes=12\n",
    "        workers=4\n",
    "        print_freq=20\n",
    "\n",
    "        # torch.manual_seed(100)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        scaler = transforms.Resize((224,224))\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225])    \n",
    "        transform= transforms.Compose([\n",
    "            scaler,\n",
    "            transforms.ToTensor(),\n",
    "            normalize       \n",
    "            ])     \n",
    "\n",
    "        testDataset = AfosrDataset(data_path,test_list,transform=transform) \n",
    "        testLoader = DataLoader(testDataset, batch_size=test_batch, shuffle=False, num_workers=workers)\n",
    "        print(\"Initializing model: {}\".format(arch))\n",
    "        model = models.init_model(name=arch, num_classes=num_classes)\n",
    "        print(\"Model size: {:.5f}M\".format(sum(p.numel() for p in model.parameters())/1000000.0))\n",
    "        checkpoint = torch.load(weightFile)\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "        # model.module.load_state_dict(checkpoint['state_dict'])\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "\n",
    "        # from ptflops import get_model_complexity_info\n",
    "        # with torch.cuda.device(0):\n",
    "        #     flops, params = get_model_complexity_info(model, (3,224,224), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
    "        #     print('{:<30}  {:<8}'.format('Computational complexity: ', flops))\n",
    "        #     print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "\n",
    "\n",
    "        fusion_matrix = FusionMatrix(num_classes)\n",
    "        func = torch.nn.Softmax(dim=1)\n",
    "        top1 = AverageMeter('Acc@1', ':6.3f')\n",
    "        top5 = AverageMeter('Acc@5', ':6.3f')\n",
    "        top10 = AverageMeter('Acc@10', ':6.3f')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            end = time.time()\n",
    "            for batch_idx,(imgs, targets) in enumerate(testLoader):\n",
    "                imgs, targets = imgs.cuda(device), targets.cuda(device)            \n",
    "                outputs, features = model(imgs)\n",
    "                result = func(outputs)\n",
    "        #         _, top_k = result.topk(10, 1, True, True)\n",
    "                score_result = result.cpu().numpy()\n",
    "                fusion_matrix.update(score_result.argmax(axis=1), targets.cpu().numpy())\n",
    "\n",
    "                acc1, acc5,acc10 = accuracy(outputs, targets, topk=(1, 5,10))            \n",
    "                top1.update(acc1[0], imgs.size(0))\n",
    "                top5.update(acc5[0], imgs.size(0))\n",
    "                top10.update(acc10[0], imgs.size(0))\n",
    "        #         topk_result = top_k.cpu().tolist()                \n",
    "        #     fig=fusion_matrix.plot_confusion_matrix(normalize = True) \n",
    "            info='%s_%s' % (arch,split)\n",
    "            print('{info}: Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f} Acc@10 {top10.avg:.3f}'\n",
    "                  .format(info=info,top1=top1, top5=top5, top10=top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b59bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cm=fusion_matrix.matrix.T\n",
    "cm=cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "np.savetxt(\"confusion_splitby_env.csv\", cm, delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=fusion_matrix.plot_confusion_matrix(normalize = False) \n",
    "f.savefig(\"confusion_splitby_env.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5443da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
